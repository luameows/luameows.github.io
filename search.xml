<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[记录-hexo博客配置]]></title>
    <url>%2F2019%2F04%2F17%2F%E8%AE%B0%E5%BD%95-hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[站点更新2018.12.07 用七牛云图床替代简书，采用MPIC快捷操作。 添加站内搜索选项。 添加不蒜子站点统计，解决不显示统计人数问题。 2018.12.06 用gitalk替换来必力评论系统。 解决gitalk编码字符过长问题 添加在线联系功能daovoice]]></content>
      <categories>
        <category>记录</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于tensorflow人脸识别]]></title>
    <url>%2F2018%2F12%2F09%2F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E5%9F%BA%E4%BA%8Etensorflow%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[参考代码: facenet, amsoftmax 个人实现: luameows/face_recongnition_tensorflow tensorflow基本概念官方解释如下 TensorFlow使用Graph来描述计算任务,图中的节点被称之为op.一个op可以接受0或多个tensor作为输入,也可产生0或多个tensor作为输出.任何一个Graph要想运行,都必须借助上下文Session.通过Session启动Graph,并将Graph中的op分发到CPU或GPU上,借助Session提供执行这些op.op被执行后,将产生的tensor返回.借助Session提供的feed和fetch操作,我们可以为op赋值或者获取数据.计算过程中,通过变量(Variable)来维护计算状态. 数据写入与读取tf.dataAPI支持多种文件格式，TFRecord文件格式是一种面向记录的简单二进制格式文件，可以用于存储数据，通过tf.dataTFRecordDataset进行操作。 参考文献:读取, 写入 数据读取123456789101112131415161718192021222324# 用tf.placeholder(tf.string)区分train与val数据集filenames = tf.placeholder(tf.string, shape=[None]) #用于指向train与val各自tfrecord文件phase_train = tf.placeholder(tf.bool, name=='phase_train') #用于判断train还是valdataset = tf.data.TFRecordDataset(filenames)#调用train数据集预处理及解析函数dataset_train = dataset.map(parse_function_train) dataset_train = dataset_train.shuffle(buffer_size=30000)dataset_train = dataset_train.batch(32)iterator_train = dataset_train.make_initializable_iterator()next_element_train = iterator_train.get_next()#调用val数据集预处理及解析函数dataset_val = dataset.map(parse_function_val) dataset_val = dataset_val.shuffle(buffer_size=30000)dataset_val = dataset_val.batch(32)iterator_val = dataset_val.make_initializable_iterator()next_element_val = iterator_val.get_next()# 获取train数据集training_filenames = ["/var/data/file1.tfrecord"]sess.run(iterator_train.initializer, feed_dict=&#123;filenames: training_filenames&#125;)images_train, labels_train = sess.run(next_element_train)# 获取val数据集validation_filenames = ["/var/data/validation1.tfrecord"]sess.run(iterator_val.initializer, feed_dict=&#123;filenames: validation_filenames&#125;)images_val, labels_val = sess.run(next_element_val) 数据存储123456789101112131415161718192021222324output_path_train = os.path.join(args.tfrecords_file_path, 'train.tfrecords')output_path_val = os.path.join(args.tfrecords_file_path, 'valid.tfrecords')writer_train = tf.python_io.TFRecordWriter(output_path_train)writer_val = tf.python_io.TFRecordWriter(output_path_val)label = 0for filename in os.listdir(args.total_train_set_path): train_i = 0 person_list = os.path.join(args.total_train_set_path, filename) for imgname in os.listdir(person_list): img = cv2.imread(os.path.join(person_list,imgname)) # 读取图片格式HWC, BGR img_raw = img.tobytes() example = tf.train.Example(features=tf.train.Features(feature=&#123; 'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])), "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])) &#125;)) if train_i &gt; len(os.path.join(args.total_train_set_path, filename) * (1-args.validation_rate): writer_val.write(example.SerializeToString()) else: writer_train.write(example.SerializeToString()) train_i += 1 label += 1 print('%s's image processed' % filename)writer_train.close()writer_val.close() fine-tune通过saver.restore(sess,ckptpath)加载预训练模型，可能会出现Key &lt;variable_name&gt; not found in checkpoint错误，即checkpoint保存的模型变量与当前网络模型变量不一致，解决办法，建立一个存储ckpt变量的字典，剔除不一致变量。 12345variables = slim.get_variables_to_restore()variables_to_restore = [v for v in variables if 'arcface' not in v.name.split('/')[0]] saver = tf.train.Saver(variables_to_restore)saver.restore(sess, ckptpath)]]></content>
      <categories>
        <category>程序开发</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Additive Margin Softmax for Face Verification]]></title>
    <url>%2F2018%2F12%2F03%2F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-amsoftmax%2F</url>
    <content type="text"><![CDATA[文献来源：Amsoftmax 代码实现：luameows/amsoftmax 文章总结： 提出amsoftmax loss 标准化系数$s$设置为定值，而不是通过学习获得 feature norm可以让网络更关注低质量图片 采用mirror trick以增加特征鲁棒性 AMSoftmax Loss损失函数公式如下$$L_{AMS}=-\frac{1}{n}\sum_{i=1}^n\log\frac{e^{s(\cos\theta_{yi}-m)}}{e^{s(\cos\theta_{yi}-m)}+\sum_{j=1}^me^{s\cos\theta_j}}$$即对输出$feature$与权重$w$进行标准化后，设置间距项$margin: m$。 注：$s$被设置为定值而非可学习参数。 再谈feature normL2-softmax loss论文中提出，feature norm的值与图片质量有关。根据反向传播法则，归一化之后，低质量图片由于拥有较小的feature norm，因而拥有较大的梯度，即网络会更关注低质量图片。这类似于hard sample mining。 mirror trick将原始图片与其水平镜像后的图片输入网络，提取特征，选取对应元素最大值构造新的特征。 问题在自己网络上实现时，发现train loss远高于val loss，且val loss走势非常理想。该部分原因尚未查明。]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NormFace--L2 hypersphere embedding for face Verification]]></title>
    <url>%2F2018%2F12%2F01%2F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-normface%2F</url>
    <content type="text"><![CDATA[文献来源：NormFace: L2 Hypersphere Embedding for Face Verification 文章总结： 提出了mirror trick，用于人脸验证 对$f$, $w$标准化，在训练时不会收敛到很小的值。 以$w_(y_i)$作为$y_i$这个class的agent 人脸识别与普通分类任务不同，人脸识别还需要考虑人脸验证这个环节，因而增大类类间距，减小类内间距是人脸识别的主要任务。目前人脸识别解决方案主要是两种思路。 Metric Learning度量学习尝试去学习特征之间距离度量方式并直接嵌入使用。常见的Contrastive Loss, Triplet Loss。 Margin Based Classification以添加强间距的方式进行分类学习。如Center Loss等。 Softmax Loss缺陷 softmax会让易区分的feature拥有更大的norm，因norm越大，对应loss越小。 对于no-bias的softmax loss，设$P_i(f)=\frac{e^{w_i^Tf}}{\sum_{j=1}^ne^{w_j^Tf}}$表示x被分类到$i$的概率。给定$s&gt;1$，若$i=\arg \max_j(w_j^Tf)$，则$P_i(sf)\geq P_i(f)$恒成立。 在人脸验证中通常采用的是归一化余弦相似度，而softmax loss训练中并未对feature，$w$进行归一化。 Feature Norm 标准化feature与$w$，若保留softmax loss中偏秩项$b$会破坏特征分布。 特征$x$与其梯度方向$\frac{\partial L}{\partial x}$正交。反向传播后，特征$x$更新为$x+\alpha \frac{\partial L}{\partial x}$，即$||x||_2$会不断增大。 仅仅对feature与$w$进行标准化操作，虽然可以统一cosine similarity与softmax的出入，但是在训练过程中发现，loss无法收敛到较小值。通过证明，对feature与norm标准化为$l$大小，softmax loss最小值为 $$\log(1+(n-1)e ^{- \frac{n}{n-1}l^2})$$ ​ 因而，norm标准化值$l$越大，对应loss下界越小。 修正后损失函数为 $$L=- \frac{1}{m}\sum_{i=1}^{m}\log\frac{e^{s{\hat w_{y_i}^T}{\hat f_i}}}{\sum_{j=1}^ne^{s{\hat w_{y_j}^T}{\hat f_j}}}$$ 标准化后的余弦距离与欧氏距离是统一的。 以$w_(y_i)$作为$y_i$这个class的agent 测试基于LFW数据集的两种测试方式。 unrestricted with labeled outside data，即6000pairs测试。 BLUFR，利用LFW全部13233张图片。]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度生物特征识别大赛-复赛]]></title>
    <url>%2F2018%2F09%2F14%2F%E6%AF%94%E8%B5%9B-%E7%99%BE%E5%BA%A6%E7%94%9F%E7%89%A9%E7%89%B9%E5%BE%81%E8%AF%86%E5%88%AB%E5%A4%A7%E8%B5%9B-%E5%A4%8D%E8%B5%9B%2F</url>
    <content type="text"><![CDATA[写在前面首届生物特征识别大赛，科赛网。内容包括吗，mtcnn进行人脸检测,matlab下仿射变换在python下的实现，数据清洗与数据均衡。 最终名次，第8。准确率94.4%。 使用paddlepaddle.fluid。 预处理1.采用mtcnn进行人脸裁剪并对齐，尽可能保留相关元素。 2.采用随机裁剪、色彩增强等方式对数据集进行上采样扩充，尽量控制数据集均衡。实验证明，均衡后的数据集训练效果更好，但是由于数据集更大，训练时间更长。 训练网络采用sphereface20-net，效果比较理想。 学习率采用warmup策略，结合early stop，有不错提升。由于数据集较大，batch size=512需要跑1300多个batch才一轮epoch，最终未能训练到最优。 整个过程主要调整参数为lr, weight decay。 尝试构造centerloss， amsoftmax均失败，原因是paddle有些接口存在bug，这个没办法，尽力了QAQ。 人脸验证采用mirror trick测试，最后max out会有较好结果，大概能提升2%~ 源码链接完整源码文件在我的github。 jupyternote book参阅kesci平台。]]></content>
      <categories>
        <category>比赛</category>
      </categories>
      <tags>
        <tag>paddle</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度生物特征识别大赛-初赛]]></title>
    <url>%2F2018%2F08%2F12%2F%E6%AF%94%E8%B5%9B-%E7%99%BE%E5%BA%A6%E7%94%9F%E7%89%A9%E7%89%B9%E5%BE%81%E8%AF%86%E5%88%AB%E5%A4%A7%E8%B5%9B-%E5%88%9D%E8%B5%9B%2F</url>
    <content type="text"><![CDATA[写在前面本文是18年8月参加科赛网的《首届生物特征识别大赛》初赛阶段相关整理。内容包括采用dlib进行人脸检测及对其的预处理，构建resnet进行人脸识别训练。 目前成绩是，13/34，已经进入复赛阶段。 使用的深度学习平台是百度paddlepaddle.v2。 先吐槽下这个API做的稀烂，相关说明文档也不够完善。 数据预处理图片统一裁剪为64x64，经过人脸检测与对齐处理。 对于训练集，若未检测到人脸，或检测人脸置信度不高，则抛弃该张图片。若检测多张人脸，选取距离中心最近，并检测置信度。 对于测试集，若未检测到人脸或置信度不高，则强制中心裁剪。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#coding:utf-8'''模型下载地址 http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'''import dlibimport os,sysimport mathimport numpy as nprootpath_test='/mnt/datasets/WebFace_fusai/testing_set/'savepath_test='/home/kesci/work/first_round/first_round_test/'rootpath_train='/mnt/datasets/WebFace_fusai/train_set/'savepath_train='/home/kesci/work/first_round/first_round_train/'rootpath_val='/mnt/datasets/WebFace_fusai/validate_set/'savepath_val='/home/kesci/work/first_round/first_round_validate/'detector=dlib.get_frontal_face_detector()sp=dlib.shape_predictor('/home/kesci/work/shape_predictor_68_face_landmarks.dat')def CheckFace(dets,height,width): num=len(dets) center_x=width/2 center_y=height/2 dist=[] for i in range(num): c_x=dlib.center(dets[i]).x c_y=dlib.center(dets[i]).y distance=math.pow(c_x-center_x,2)+math.pow(c_y-center_y,2) dist.append(distance) return dist.index(min(dist))#该部分代码应用于test文件夹，对于val与train应使用下面被注释部分for class_num in os.listdir(rootpath_test): if class_num=='.DS_Store': continue imgpath=rootpath_test+class_num img=dlib.load_rgb_image(imgpath) faces=dlib.full_object_detections() #检测人脸，若超过1张，选取中心最近,若没检测到，中心裁剪 dets,scores,idx=detector.run(img,1,-1) index=0 if len(dets)&gt;1: index=CheckFace(dets,img.shape[0],img.shape[1]) if len(dets)==1: index=0 if len(dets)==0 or scores[index]&lt;0.75: #强制中心裁剪 img=img[50:200,50:200] img=dlib.resize_image(img,128,128) dlib.save_image(img,savepath_test+class_num) continue #人脸对齐 for detection in dets: faces.append(sp(img,detection)) images = dlib.get_face_chips(img, faces, size=128) dlib.save_image(images[index],savepath_test+class_num)print "finish test file" for class_num in os.listdir(rootpath_train): if class_num=='.DS_Store': continue imgclass=rootpath_train+class_num+'/' if not os.path.exists(savepath_train+class_num): os.mkdir(savepath_train+class_num) for img_name in os.listdir(imgclass): imgpath=imgclass+img_name img=dlib.load_rgb_image(imgpath) faces=dlib.full_object_detections() #检测人脸，若超过1张，选取中心最近,若没检测到，中心裁剪 dets,scores,idx=detector.run(img,1,-1) index=0 if len(dets)&gt;1: index=CheckFace(dets,img.shape[0],img.shape[1]) if len(dets)==1: index=0 if len(dets)==0 or scores[index]&lt;0.75: #强制中心裁剪 img=img[50:200,50:200] img=dlib.resize_image(img,128,128) dlib.save_image(img,savepath_train+class_num+'/'+img_name) continue #人脸对齐 for detection in dets: faces.append(sp(img,detection)) images = dlib.get_face_chips(img, faces, size=128) dlib.save_image(images[index],savepath_train+class_num+'/'+img_name)print "finish train file"for class_num in os.listdir(rootpath_val): if class_num=='.DS_Store': continue imgclass=rootpath_val+class_num+'/' if not os.path.exists(savepath_val+class_num): os.mkdir(savepath_val+class_num) for img_name in os.listdir(imgclass): imgpath=imgclass+img_name img=dlib.load_rgb_image(imgpath) faces=dlib.full_object_detections() #检测人脸，若超过1张，选取中心最近,若没检测到，中心裁剪 dets,scores,idx=detector.run(img,1,-1) index=0 if len(dets)&gt;1: index=CheckFace(dets,img.shape[0],img.shape[1]) if len(dets)==1: index=0 if len(dets)==0 or scores[index]&lt;0.75: #强制中心裁剪 img=img[50:200,50:200] img=dlib.resize_image(img,128,128) dlib.save_image(img,savepath_val+class_num+'/'+img_name) continue #人脸对齐 for detection in dets: faces.append(sp(img,detection)) images = dlib.get_face_chips(img, faces, size=128) dlib.save_image(images[index],savepath_val+class_num+'/'+img_name)print "finish val file" 构建数据集主要是对数据集进行均衡处理，默认50张为基准线。对低于50张的类别，进行随机上采样完成数据扩充。 利用paddle构建DL网络由于数据量少，且官方在初赛阶段只提供GPU，因而采用resent结构进行网络训练。 123456#coding: utf-8import paddle.v2 as paddleimport numpy as npfrom PIL import Imageimport os, sysfrom multiprocessing import cpu_count 对于v2版本的paddle使用说明，主要包括几个大部分。 网络构建构建resnet_network，定义损失函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def resnet(ipt,class_dim=1017): def conv_bn_layer(input, ch_out, filter_size, stride, padding, active_type=paddle.activation.Relu(), ch_in=None): tmp = paddle.layer.img_conv( input=input, filter_size=filter_size, num_channels=ch_in, num_filters=ch_out, stride=stride, padding=padding, act=paddle.activation.Linear(), bias_attr=False) return paddle.layer.batch_norm(input=tmp, act=active_type, moving_average_fraction=0.999) def shortcut(ipt, ch_in, ch_out, stride): if ch_in != ch_out: return conv_bn_layer(ipt, ch_out, 1, stride, 0, paddle.activation.Linear()) else: return ipt def basicblock(ipt, ch_in, ch_out, stride): tmp = conv_bn_layer(ipt, ch_out, 3, stride, 1) tmp = conv_bn_layer(tmp, ch_out, 3, 1, 1, paddle.activation.Linear()) short = shortcut(ipt, ch_in, ch_out, stride) return paddle.layer.addto(input=[tmp, short], act=paddle.activation.Relu()) def layer_warp(block_func, ipt, ch_in, ch_out, count, stride): tmp = block_func(ipt, ch_in, ch_out, stride) for i in range(1, count): tmp = block_func(tmp, ch_out, ch_out, 1) return tmp # resnet n = 1 feature_maps = 128 ipt_bn = ipt - 128.0 conv1 = conv_bn_layer(ipt_bn, ch_in=1, ch_out=4, filter_size=3, stride=1, padding=1) res1 = layer_warp(basicblock, conv1, 4, 8, n, 1) res2 = layer_warp(basicblock, res1, 8, 16, n, 2) res3 = layer_warp(basicblock, res2, 16, 32, n, 2) res4 = layer_warp(basicblock, res3, 32, 64, n, 2) res5 = layer_warp(basicblock, res4, 64, feature_maps, n, 2) pool = paddle.layer.img_pool(input=res5, name='pool', pool_size=4, stride=1, pool_type=paddle.pooling.Avg()) fc = paddle.layer.fc(input=pool, size=class_dim, act=paddle.activation.Softmax()) return pool, fcdef resnet_loss(datadim,num_class): img=paddle.layer.data(name='image',type=paddle.data_type.dense_vector(datadim)) label=paddle.layer.data(name='label',type=paddle.data_type.integer_value(num_class)) fea,fc=resnet(img,class_dim=num_class) cost = paddle.layer.classification_cost(input=fc, label=label) return cost 数据读入readerpaddle通过reader进行数据读取操作。 1234567891011121314151617181920212223242526272829303132333435def train_mapper(sample): path,label=sample img=paddle.image.load_image(path,is_color=False) img=img.reshape(img.shape[0],img.shape[1],1) img=paddle.image.to_chw(img) img=img.flatten().astype('float32') return img,label def test_mapper(sample): path,label=sample img=paddle.image.load_image(path,is_color=False) img=img.reshape(img.shape[0],img.shape[1],1) img=paddle.image.to_chw(img) img=img.flatten().astype('float32') return img,label def train_reader(train_list,buffered_size=4000): def reader(): with open(train_list,'r') as f: lines = [line.strip() for line in f] for line in lines: img_path, lab = line.strip().split('|') yield img_path, int(lab) return paddle.reader.xmap_readers(train_mapper, reader, cpu_count(), buffered_size) def test_reader(test_list,buffered_size=4000): def reader(): with open(test_list,'r') as f: lines = [line.strip() for line in f] for line in lines: img_path, lab = line.strip().split('|') yield img_path, int(lab) return paddle.reader.xmap_readers(test_mapper, reader, cpu_count(), buffered_size) 进行训练该部分包括，读取mini-batch，进行shuffle，设置优化选项。定义事件处理函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960optimizer = paddle.optimizer.Momentum(momentum=0.9, regularization=paddle.optimizer.L2Regularization( rate=0.0002*128), learning_rate=0.01/128, learning_rate_decay_a=0.1, learning_rate_decay_b=60000*10, learning_rate_schedule="discexp" )def resnet_train(datadim, num_class, num_passes, model_save_dir, trainpath,testpath,readfromtar=False): cost=resnet_loss(datadim,num_class) with open(model_save_dir,'r') as f: parameters=paddle.parameters.Parameters.from_tar(f) #parameters=paddle.parameters.create(cost) trainreader = paddle.batch(paddle.reader.shuffle(train_reader(trainpath), buf_size=40000), batch_size=256) testreader = paddle.batch(test_reader(testpath),batch_size=128) trainer = paddle.trainer.SGD(cost=cost, parameters=parameters, update_equation=optimizer) feeding=&#123;'image':0,'label':1&#125; def event_handler(event): min_cost=0.446815 if isinstance(event,paddle.event.EndIteration): if event.batch_id % 2==0: print "\nPass %d, Batch %d, Cost %f, %s" %( event.pass_id,event.batch_id,event.cost,event.metrics) if event.batch_id % 10==0: if event.cost &lt; min_cost: min_cost = event.cost with open(model_save_dir,'w') as f: trainer.save_parameter_to_tar(f) if isinstance(event,paddle.event.EndPass): #测试准确率 result=trainer.test(reader=testreader,feeding=feeding) print "\nTest with Pass %d, Cost %f,, %s" %( event.pass_id,result.cost, result.metrics) trainer.train(reader=trainreader, event_handler=event_handler, num_passes=num_passes, feeding=feeding)parameters_path = "/home/kesci/work/model/model.tar"imageSize=64datadim=1*imageSize*imageSizenum_class=1017paddle.init(use_gpu=False, trainer_count=4)trainpath='/home/kesci/work/train.txt'testpath='/home/kesci/work/val.txt'resnet_train(datadim,num_class,100,parameters_path,trainpath,testpath,True) 数据提交123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136import paddle.v2 as paddleimport numpy as npfrom PIL import Imageimport os, sysfrom multiprocessing import cpu_countimport csvpaddle.init(use_gpu=0,trainer_count=1)def resnet(ipt,class_dim=1258): def conv_bn_layer(input, ch_out, filter_size, stride, padding, active_type=paddle.activation.Relu(), ch_in=None): tmp = paddle.layer.img_conv( input=input, filter_size=filter_size, num_channels=ch_in, num_filters=ch_out, stride=stride, padding=padding, act=paddle.activation.Linear(), bias_attr=False) return paddle.layer.batch_norm(input=tmp, act=active_type, moving_average_fraction=0.999) def shortcut(ipt, ch_in, ch_out, stride): if ch_in != ch_out: return conv_bn_layer(ipt, ch_out, 1, stride, 0, paddle.activation.Linear()) else: return ipt def basicblock(ipt, ch_in, ch_out, stride): tmp = conv_bn_layer(ipt, ch_out, 3, stride, 1) tmp = conv_bn_layer(tmp, ch_out, 3, 1, 1, paddle.activation.Linear()) short = shortcut(ipt, ch_in, ch_out, stride) return paddle.layer.addto(input=[tmp, short], act=paddle.activation.Relu()) def layer_warp(block_func, ipt, ch_in, ch_out, count, stride): tmp = block_func(ipt, ch_in, ch_out, stride) for i in range(1, count): tmp = block_func(tmp, ch_out, ch_out, 1) return tmp # resnet n = 1 feature_maps = 256 ipt_bn = ipt - 128.0 conv1 = conv_bn_layer(ipt_bn, ch_in=1, ch_out=4, filter_size=3, stride=1, padding=1) res1 = layer_warp(basicblock, conv1, 4, 8, n, 1) res2 = layer_warp(basicblock, res1, 8, 16, n, 2) res3 = layer_warp(basicblock, res2, 16, 32, n, 2) res4 = layer_warp(basicblock, res3, 32, 64, n, 2) res5 = layer_warp(basicblock, res4, 64, feature_maps, n, 2) pool = paddle.layer.img_pool(input=res5, name='pool', pool_size=4, stride=1, pool_type=paddle.pooling.Avg()) drop = paddle.layer.dropout(input=pool,dropout_rate=0.5) fc = paddle.layer.fc(input=drop, size=class_dim, act=paddle.activation.Softmax()) return pool, fcdef resnet_loss(datadim,num_class): img=paddle.layer.data(name='image',type=paddle.data_type.dense_vector(datadim)) label=paddle.layer.data(name='label',type=paddle.data_type.integer_value(num_class)) fea,fc=resnet(img,class_dim=num_class) cost = paddle.layer.classification_cost(input=fc, label=label) return cost def val(datadim,num_class,model_path): img=paddle.layer.data(name='image',type=paddle.data_type.dense_vector(datadim)) label=paddle.layer.data(name='label',type=paddle.data_type.integer_value(num_class)) fea,fc=resnet(img,class_dim=num_class) def load_image(file): img1=paddle.image.load_image(file,is_color=False) img1=img1.reshape(img1.shape[0],img1.shape[1],1) img1=paddle.image.resize_short(img1,64) img1=img1.reshape(img1.shape[0],img1.shape[1],1) img1=paddle.image.to_chw(img1) img1=img1.flatten().astype('float32') return img1 def cosine_distance(vector1,vector2): vector1=vector1.reshape([-1]) vector2=vector2.reshape([-1]) cos_dist=np.dot(vector1,vector2)/(np.linalg.norm(vector1)*np.linalg.norm(vector2)) score=0.5*cos_dist+0.5 return score with open(model_path,'r') as f: parameters=paddle.parameters.Parameters.from_tar(f) infile=open('/mnt/datasets/WebFace/first_round/first_round_pairs_id.txt','r') csv_file_path='/home/kesci/work/myresult.csv' img_root_path='/home/kesci/work/first_round_test/' testdata1,testdata2=[],[] fea1,fea2=[],[] img_pair=[] count=0 for pairname in infile.readlines(): if pairname=='pairs_id\n': continue count+=1 img_pair.append(pairname.strip()) img_name1,img_name2=pairname.strip().split('_') img_path1=img_root_path+img_name1+'.jpg' img_path2=img_root_path+img_name2+'.jpg' #print img_path1,img_path2 img1=load_image(img_path1) img2=load_image(img_path2) testdata1.append([img1]) testdata2.append([img2]) if count % 100 ==0: for i in paddle.infer(output_layer=fea,parameters=parameters,input=testdata1): fea1.append(i) for i in paddle.infer(output_layer=fea,parameters=parameters,input=testdata2): fea2.append(i) testdata1,testdata2=[],[] num_feature=len(fea1) score=[cosine_distance(np.asarray(fea1[i]),np.asarray(fea2[i])) for i in range(num_feature)] csvFile = open(csv_file_path,'wb') # 设置newline，否则两行之间会空一行 writer = csv.writer(csvFile) writer.writerow(['submit_pairsID','prob']) for i in range(num_feature): writer.writerow([img_pair[i],score[i]]) csvFile.close() infile.close()datadim=1*64*64num_class=1258model_path='/home/kesci/work/upload_model/classification.tar'val(datadim,num_class,model_path)]]></content>
      <categories>
        <category>比赛</category>
      </categories>
      <tags>
        <tag>paddle</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GPU下tensorflow相关环境配置]]></title>
    <url>%2F2018%2F08%2F01%2F%E8%AE%B0%E5%BD%95-GPU%E4%B8%8Btensorflow%E7%9B%B8%E5%85%B3%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[由于某些原因，需要在另一台电脑重装tensorflow，在此记录一下，便于日后查询。 安装CUDA+CUDNN安装nvidia驱动 官网下载对应驱动 删除旧驱动 1sudo apt-get purge nvidia* 禁用自带nouveau nvidia驱动 1).创建一个文件，sudo vi /etc/modprobe.d/blacklist-nouveau.conf并添加如下内容： 12blacklist nouveauoptions nouveau modeset=0 更新配置文件 1sudo update-initramfs -u 2).重启系统，切换tty1控制台Ctrl+Alt+F1，关闭X-server 1sudo service lightdm stop 3).安装驱动 1sudo ./NVIDIA.run 4).测试安装是否成功 12nvidia-sminvidia-settings 安装CUDA9.0 官网下载对应版本，调用sudo sh cuda_9.0.run进行安装。安装过程注意不要再安装驱动以免覆盖。 重启系统sudo reboot，配置环境变量sudo gedit /etc/profile，在文件末尾添加路径 12export PATH=/usr/local/cuda-9.0/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64$LD_LIBRARY_PATH 保存后，重启电脑 测试CUDA 123cd /usr/local/cuda-9.0/samples/1_Utilities/deviceQuerysudo make./deviceQuery 安装CUDNN官网下载对应安装包，通过sudo dpkg -i libcudnn.deb进行安装。 注意tensorflow-gpu-1.5要求cudnn版本7.0.x 卸载cudnn由于通过dpkg进行cudnn安装，此处需采用对应方法进行卸载. 通过dpkg -l | grep cudnn查找安装名，此处为libcudnn7，随后通过sudo dpkg -P libcudnn7进行卸载。 安装anaconda官网下载相应版本即可。 windows下使用会出现CondaHTTPError问题，如果替换镜像源不能解决，可下载清华镜像版本的anaconda。 系统内置python与conda python替换由于linux系统内置python2.7，而安装了anaconda后会得到其他版本python，在~/.bashrc配置环境变量后，终端调用python会优先搜索指定路径，即对如下配置，将调用anaconda下Python版本。 1export PATH=/home/user/anaconda3/bin:$PATH 解决办法是采用别名声明alias。 将系统自带python声明为py2，将anaconda携带python声明为pyana。 12alias py2=/usr/bin/python2.7alias pyana=/home/user/anaconda3/bin/python3.6 之后更新配置 1source ~/.bashrc 安装TensorFlow建立专用运行环境为TensorFlow创建单独使用的环境。 1conda create -n tensorflow pip python=3.5 启动tensorflow环境 1source activate tensorflow 关闭tensorflow环境 1source deactivate tensorflow 安装tensorflow官方提供的安装方法需要访问google.api，但是国内被墙，没法下载相应软件包。可以直接pip install 1pip install tensorflow-gpu==1.5 为jupyter notebook创建虚拟环境12#退出虚拟环境conda install nb_conda 但是在调用中仍然无法调用tensorflow虚拟环境，原因在于jupyter对应于主环境下。可通过which jupyter验证。解决方案，在tensorflow环境下安装jupyter与ipython，不能使用pip安装。 12(tensorflow) conda install ipython(tensorflow) conda install jupyter]]></content>
      <categories>
        <category>记录</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[利用cpp提取caffe特征]]></title>
    <url>%2F2018%2F07%2F04%2F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E5%88%A9%E7%94%A8cpp%E6%8F%90%E5%8F%96caffe%E7%89%B9%E5%BE%81%2F</url>
    <content type="text"><![CDATA[写在前面由于项目需要，利用caffe的cpp接口提取隐含层特征。 这里记录踩过的坑。 最终基于python与基于classification.cpp提取的特征保持一致，相关完整代码已整合github。 opencv与caffe一切的起源在于，利用opencv的dnn模块读取caffe模型，最终提取特征与利用caffe的python接口提取的特征不同。 opencv接口123456789101112131415161718#include &lt;opencv2/dnn/dnn.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/core/utils/trace.hpp&gt;using namespace cv;using namespace cv::dnn;CV_TRACE_FUNCTION();String modelTxt = "ResNet11.prototxt";String modelBin = "ResNet11.caffemodel";String probfile = "./jpegFile/prob.jpg";Net net = dnn::readNetFromCaffe(modelTxt, modelBin);Mat img = imread(imgFile.c_str());Mat inputBlob = blobFromImage(img, 1, Size(96, 96),Scalar(119.935, 119.935, 119.935));CV_TRACE_REGION("forward");net.setInput(inputBlob, "data");Mat prob = net.forward("fc1"); python接口1.caffe.io.load_image()读取图片为RGB格式，而caffenet输入图片为BGR格式。采用opencv的cv::imread()读取的图片即为BGR格式。 2.由于python通过np.load()读取均值文件，因而在prototxt中应剔除mean_file相关配置，这就是踩的一个大坑.. 12345678910111213141516171819202122232425262728293031323334353637import numpy as npimport syscaffe_root='/home/user/caffe/'sys.path.insert(0,caffe_root+'python')import caffeimport os# 初始化并加载caffe模型caffe.set_mode_cpu()model_def = '/home/user/extract_feature/py_deploy.prototxt'model_weights='/home/user/extract_feature/ResNet11.caffemodel'net = caffe.Net(model_def, # defines the structure of the model model_weights, # contains the trained weights caffe.TEST) # use test mode (e.g., don't perform dropout)mu=np.load('/home/user/extract_feature/mean.npy') #读取均值文件mu = mu.mean(1).mean(1)print 'mean-subtracted values:', zip('BGR', mu)# caffe输入图片格式为BGR，因此需要对输入数据进行预处理操作transformer = caffe.io.Transformer(&#123;'data': net.blobs['data'].data.shape&#125;)transformer.set_transpose('data', (2,0,1)) # move image channels to outermost dimensiontransformer.set_mean('data', mu) # subtract the dataset-mean value in each channeltransformer.set_raw_scale('data', 255) # rescale from [0, 1] to [0, 255]transformer.set_channel_swap('data', (2,1,0)) # swap channels from RGB to BGR# set the size of the input (we can skip this if we're happy# with the default; we can also change it later, e.g., for different batch sizes)net.blobs['data'].reshape(3, 3, 96, 96) image = caffe.io.load_image('/home/user/extract_feature/img/img_3.jpg')transformed_image = transformer.preprocess('data', image)net.blobs['data'].data[...] = transformed_image### perform classificationoutput = net.forward()feature=net.blobs['fc1'].data[0]filehandle=open('py_out.txt','a')filehandle.write(' '.join(str(a) for a in feature))filehandle.write('\n')filehandle.close CPP相关API接口参考链接，examples/cpp_classification/classification.cpp，tools/extract_feature.cpp 初始化网络1234567891011121314151617181920212223#include "caffe/caffe.hpp"#include &lt;string&gt;//其他头文件#include &lt;algorithm&gt;#include &lt;iosfwd&gt;#include &lt;memory&gt;#include &lt;utility&gt;#include &lt;vector&gt;using namespace caffe;string model_file="deploy.prototxt";string model_weight="resnet.caffemodel";string mean_file="mean.binaryproto";//选择计算方式#ifdef CPU_ONLY Caffe::set_mode(Caffe::CPU);#else Caffe::set_mode(Caffe::GPU);//初始化网络shared_ptr&lt;Net&lt;float&gt; &gt; net.reset(new Net&lt;float&gt;(model_file,TEST));//加载网络参数net-&gt;CopyTrainedLayersFrom(model_weight); 读取图像均值123456789101112131415161718192021222324BlobProto blob_proto;ReadProtoFromBinaryFileOrDie(mean_file.c_str(), &amp;blob_proto);//将BlobProto转化为Blob&lt;float&gt;Blob&lt;float&gt; mean_blob;mean_blob.FromProto(blob_proto);//将均值文件转化为cv::Mat格式#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;std::vector&lt;cv::Mat&gt; channels;float* data = mean_blob.mutable_cpu_data();//按通道将mean文件单独抽取for (int i = 0; i &lt; num_channels_; ++i) &#123; cv::Mat channel(mean_blob.height(), mean_blob.width(), CV_32FC1, data); channels.push_back(channel); data += mean_blob.height() * mean_blob.width();&#125;cv::Mat mean;cv::merge(channels, mean);cv::Scalar channel_mean = cv::mean(mean);//最终获得Mat形式meancv::Mat mean_ = cv::Mat(input_geometry_, mean.type(), channel_mean); 利用opencv读取图像并进行预处理其中的input_channels需要WrapInputLayer处理，具体函数功能没有弄清，先摆出来。 12345678910111213141516171819202122void Classifier::WrapInputLayer(std::vector&lt;cv::Mat&gt;* input_channels) &#123; Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0]; int width = input_layer-&gt;width(); int height = input_layer-&gt;height(); float* input_data = input_layer-&gt;mutable_cpu_data(); for (int i = 0; i &lt; input_layer-&gt;channels(); ++i) &#123; cv::Mat channel(height, width, CV_32FC1, input_data); input_channels-&gt;push_back(channel); input_data += width * height; &#125;&#125;string file="lena.jpg";cv::Mat img=cv::imread(file,-1);//区分灰度图像，尺寸信息等略过//减去均值文件cv::Mat sample_normalized;cv::substract(img,mean_,sample_normalized);cv::split(sample_normalized, *input_channels); 根据名称提取对应层特征123456789101112Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0];input_layer-&gt;Reshape(1, num_channels_, input_geometry_.height, input_geometry_.width);net-&gt;Reshape();std::vector&lt;cv::Mat&gt; input_channels;WrapInputLayer(&amp;input_channels);net-&gt;Forward();//根据名称提取对应层特征const shared_ptr&lt;Blob&lt;float&gt; &gt;output_layer = net_-&gt;blob_by_name("fc1");const float* begin = output_layer-&gt;cpu_data();const float* end = begin + output_layer-&gt;channels();std::vector&lt;float&gt; feature_out = new std::vector&lt;float&gt;(begin, end); cpp提取caffe特征caffe自带两个例程可以用来提取某一层的特征。 examples/cpp_classification/classification.cpp原本是一个用来输出最后一层分类结果的例程。 tools/extract_feature.cpp读取lmdb数据或图片数据，提取所需层特征，并保存为lmdb格式。 lmdb读取目前搜索结果，读取lmdb只有采用python的lmdb模块。相关代码参考1，代码参考2 但测试发现，解析的特征与例程相距甚远。 相关解释为python中lmdb数据存放以key值按照字母排序整理，而caffe中似乎按照value大小进行整理。]]></content>
      <categories>
        <category>程序开发</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>C++</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于landmark疲劳检测]]></title>
    <url>%2F2018%2F06%2F14%2F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E5%9F%BA%E4%BA%8Elandmark%E7%96%B2%E5%8A%B3%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[写在前面一个小项目，基于landmark眼睛检测判断是否疲劳驾驶。 整个工程用到的库包括如下 123import dlib #调用HOG-based face landmarkimport cv2import imutils #对opencv简化，更方便使用 相关源码及文件已同步至github-detect_drowsiness Windows安装dlibwindows下采用pip install 安装dlib会报错，目前采用的安装方式为，先安装cmake， boost， 再下载dlib进行安装。 直接采用.whl安装即可。download 算法 基于landmark实现对人眼定位，通过计算纵宽比(EAR)判断睁眼还是闭眼。 代码实现主要包括几个模块。 face landmark该部分利用dlib库，基于HOG特征训练的人脸检测器及特征点定位。 123import dlibdetector=dlib.get_frontal_face_detector()#采用dlib人脸检测predictor=dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')载入模型进行landmark EAR计算该部分采用imutils库，是一个基于opencv与matplot便捷使用库。 总结该部分只是一个基于face landmark的功能扩展，其核心部分仍在于如何快速准确定位人脸及特征点标记。]]></content>
      <categories>
        <category>程序开发</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于deep-learning的人脸识别系统]]></title>
    <url>%2F2018%2F05%2F06%2F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[写在前面由于教研室项目要求，整个系统构造如下。即利用NPD检测人脸，经过去重过滤操作后，上传至服务器，随后在接收端保留接收图片，进行仿射变换预处理，随后导入训练好的神经网络，提取特征完成人脸识别。 本篇主要涉及内容： 1.ubuntu下安装opencv及相关配置 1.服务器接收图片压入队列 2.新线程读取队列，完成人脸识别操作 3.测试函数，模拟接收图片。即，windows与linux下扫描文件夹。 安装opencv主要参考教程ubuntu16.04安装opencv3.4.1教程 。 编译cpp利用g++或gcc编译程序时，需调用opencv依赖项。 1.找到lib存储路径，默认路径为/usr/local/lib/pkgconfig 2.加入环境变量 1user@ubuntu:~$ gedit .bashrc 将上述路径加入最底部。 3.编译程序命令 1user@ubuntu:~$ g++ -o test test.cpp `pkg-config --cflags --libs opencv` 扫描文件夹windows需要包含库文件#include&lt;io.h&gt;。主要用到结构体_finddata_t，函数_findfirst(), _findnext(), _findclose()。若文件夹为动态，需不停遍历。 1.结构体_finddata_t可以用来获取文件各种信息。 12345678struct _finddata_t&#123; unsigned attrib; //文件属性 time_t time_create; //创建时间 time_t time_access; //最后一次访问时间 time_t time_write; //最后一次修改时间 _fsize_t size; //文件大小 char name[260]; //文件名&#125;； 2._findfirst函数long _findfirst(const char *filename, struct _finddata_t *fileinfo); 参数： filename，查找路径下文件名，可以用*.*查找所有文件，*.jpg查找所有.jpg文件。注意*将查找.与.. fileinfo，_finddata_t结构体指针，无须初始化。若查找成功，将当前文件信息传入该结构体。 输出：查找成功，返回文件句柄；失败，返回-1。 3._findnext函数int _findnext(long hfile, struct _finddata_t * fileinfo); 参数： hfile，文件句柄。函数会依据当前句柄寻找下一个文件 fileinfo，_finddata_t结构体指针。若查找成功，将当前文件信息传入该结构体。 输出：查找成功，返回0；失败，返回-1。 4._findclose()函数int _findclose(long); 只有一个参数，文件句柄。若关闭成功返回0，失败返回-1。 12345678910111213141516171819202122232425262728#include&lt;io.h&gt;#include&lt;string&gt;#include&lt;iostream&gt;using namespace std;int main()&#123; string tarpath="G:\\pic\\positive"; //遍历文件夹 string p;//字符串，存放路径 long hFile = 0;//文件句柄 struct _finddata_t fileinfo;//文件信息，声明一个存储文件信息的结构体 //若查找成功，则进入 if ((hFile = _findfirst(p.assign(tarpath).append("\\*").c_str(), &amp;fileinfo)) != -1)&#123; do&#123; //如果是目录,迭代之（即文件夹内还有文件夹） //cout &lt;&lt; hFile &lt;&lt; endl; if ((fileinfo.attrib &amp; _A_SUBDIR))&#123; //文件名不等于"."&amp;&amp;文件名不等于".." //.表示当前目录 //..表示当前目录的父目录 //判断时，两者都要忽略，不然就无限递归跳不出去了！ if (strcmp(fileinfo.name, ".") != 0 &amp;&amp; strcmp(fileinfo.name, "..") != 0) getFiles(p.assign(path).append("\\").append(fileinfo.name), files); &#125; else&#123; cout&lt;&lt;fileinfo.name&lt;&lt;endl; &#125; &#125;while((_findnext(hFile, &amp;fileinfo) == 0)); ——findclose(hFile);&#125; linux平台linux下文件没有创建时间的说法。其读取文件顺序与文件名无关，默认按照文件写在磁盘上的位置。主要用到结构体DIR, stat, dirent, 函数opendir, readdir, closedir。 1.使用opendir打开目录a，返回指向目录的目录流dir 2.readdir(dir)读取目录流，更新下一个文件的目录流，将当前文件信息存于dirent结构体中 3.调用stat（d-&gt;name,stat *e） 或dirent结构体获取文件信息。 需要包含的库。 1234#include&lt;unistd.h&gt;#include&lt;sys/types.h&gt;#include&lt;dirent.h&gt;#include&lt;sys/stat.h&gt; 1.结构体DIR DIR结构体类似于FILE，是一个内部结构，主要用于opendir, readdir, closedir等函数。 2.结构体dirent，主要起着一个索引的作用。 12345678struct dirent&#123; long d_ino; /* inode number 索引节点号 */ off_t d_off; /* offset to this dirent 在目录文件中的偏移，默认排序方式 */ unsigned short d_reclen; /* length of this d_name 文件名长 */ unsigned char d_type; /* the type of d_name 文件类型 */ char d_name [NAME_MAX+1]; /* file name (null-terminated) 文件名，最长255字符 */&#125; 3.结构体stat 123456789101112131415struct stat &#123; mode_t st_mode; //文件访问权限 ino_t st_ino; //索引节点号 dev_t st_dev; //文件使用的设备号 dev_t st_rdev; //设备文件的设备号 nlink_t st_nlink; //文件的硬连接数 uid_t st_uid; //所有者用户识别号 gid_t st_gid; //组识别号 off_t st_size; //以字节为单位的文件容量 time_t st_atime; //最后一次访问该文件的时间 time_t st_mtime; //最后一次修改该文件的时间 time_t st_ctime; //最后一次改变该文件状态的时间 blksize_t st_blksize; //包含该文件的磁盘块的大小 blkcnt_t st_blocks; //该文件所占的磁盘块 &#125;; 4.opendir函数DIR * opendir(const char *name); 参数： name，需要打开的文件路径 输出：成功，返回DIR*形态的目录流；失败，返回NULL 5.readdir函数struct dirent * readdir(DIR* dir); 参数： dir，读取目录流 输出： 成功则返回下个目录进入点。有错误发生或读取到目录文件尾则返回NULL 。 6.closedir函数int closedir(DIR* dir); 参数： dir，读取目录流 输出：关闭成功则返回0，失败返回-1，错误原因存于errno 中。 1234567891011121314151617181920212223242526#include&lt;unistd.h&gt;#include&lt;sys/types.h&gt;#include&lt;dirent.h&gt;#include&lt;sys/stat.h&gt;using namespace std;int main()&#123; const char* dir_name = "./sample"; //要读取文件路径 struct dirent * filename; // 存储文件信息结构体 DIR * dir; // 目录流 strtuct stat statbuf; //stat结构体，存储更详细文件信息 dir = opendir( dir_name ); if(dir==NULL)&#123; cout&lt;&lt;"open dir error"&lt;&lt;endl; &#125; while( ( filename = readdir(dir) ) != NULL )&#123; if( strcmp( filename-&gt;d_name , "." ) == 0 ||strcmp( filename-&gt;d_name , "..") == 0 )//判断"."与".." continue; string name=filename-&gt;d_name; //利用dirent结构体获取文件名 string path; path.assign("./sample/").append(name); //当前文件访问路径 stat(filename,&amp;statbuf); //利用dirent获取文件stat结构信息 &#125; closedir(dir); return 0; &#125; 多线程编程参考文档unix linux多线程编程， pthread_create函数的详细讲解 ，C++ 多线程并发控制——互斥锁 pthread_mutex 。 linux下需调用依赖库#include&lt;pthread&gt;，该依赖项不是linux默认库。在编译时，需添加-lpthread参数，调用静态链接库。 创建线程1234int pthread_create(pthread_t *restrict thread, const pthread_attr_t *restrict attr, void*（*start_routine)(void*), void *restrict arg); 参数thread指向保存线程ID的pthread_t结构。参数attr表示一个封装了线程属性的对象，用来配置线程的运行，如果为NULL，线程使用默认属性。参数start_routine是线程开始执行时调用的函数名。该函数必须具有以下格式，void* start_routine(void* arg);。参数arg表示传递给函数的参数。如果需要向start_routine函数传递的参数不止一个，那么需要把这些参数放到一个结构中，然后把这个结构的地址作为arg的参数传入。 互斥锁为了防止不同线程同时操作任务队列，应在一个线程读写队列时，将队列上锁。 初始化int pthread_mutex_init(pthread_mutex_t *mp, const pthread_mutexattr_t *mattr) 参数： mp，互斥锁地址 mattr，锁属性，默认null。 如果互斥锁已初始化，则它会处于未锁定状态 。 锁定互斥锁int pthread_mutex_lock(pthread_mutex_t *mutex); 参数： mutex，互斥锁地址 函数返回时，互斥锁被锁定。调用线程是该互斥锁的属主。如果该互斥锁已被另一个线程锁定和拥有，则调用线程将阻塞，直到该互斥锁变为可用为止。 解除互斥锁int pthread_mutex_unlock(pthread_mutex_t *mutex); 参数： mutex，互斥锁地址 程序源码说明：main函数模拟服务器接收数据，即每间隔1s读取一张图片，并送入队列。新建线程进行人脸匹配识别操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212//////////////////////////////////////////////////////////////////////// // file_server.c -- // ///////////////////////////////////////////////////////////////////// #include&lt;netinet/in.h&gt; #include&lt;sys/types.h&gt; #include&lt;sys/socket.h&gt; #include&lt;stdio.h&gt; #include&lt;stdlib.h&gt; #include&lt;string.h&gt; #include&lt;queue&gt;//thread#include"pthread.h"#include&lt;unistd.h&gt;//need by read() function//opencv#include &lt;opencv2/dnn/dnn.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/core/utils/trace.hpp&gt;using namespace cv;using namespace cv::dnn;//test#include&lt;unistd.h&gt;#include&lt;dirent.h&gt;#include&lt;sys/stat.h&gt;#include&lt;iostream&gt;#define SERVER_PORT 10001 #define LENGTH_OF_LISTEN_QUEUE 20 #define BUFFER_SIZE 96*1024 #define FILE_NAME_MAX_SIZE 512 //task to be transported to queuestruct CTask &#123; std::string m_name; Mat m_data;&#125;;//lockpthread_mutex_t mutex;std::queue&lt;CTask&gt; QTask;Mat extractFeature(const String &amp;imgFile,Net &amp;net) &#123; Mat img = imread(imgFile.c_str()); printf("\t\tread img file...\n"); if (img.empty()) &#123; printf("\t\tCan't read image from the file: %s\n" , imgFile.c_str() ); &#125; Mat inputBlob = blobFromImage(img, 1, Size(96, 96), Scalar(127, 127, 127)); //Convert Mat to batch of images printf("\t\tconvert inputBlob successfully\n"); CV_TRACE_REGION("forward"); net.setInput(inputBlob, "data"); //set the network input Mat prob = net.forward("fc1"); printf("\t\tforward calculate successfully\n"); return prob;&#125;void *queWork(void*arg) &#123; //******************initialize the deep-learning net work and extract prob feature********** printf("thread create successfully!\tStart initialize dp network\n"); //std::queue&lt;CTask&gt; QTask = *(std::queue&lt;CTask&gt;*)arg; CV_TRACE_FUNCTION(); String modelTxt = "ResNet11.prototxt"; String modelBin = "ResNet11.caffemodel"; String probfile = "./jpegFile/prob.jpg"; Net net = dnn::readNetFromCaffe(modelTxt, modelBin); if (net.empty()) &#123; printf("\tCan't load network by using the following files: \nprototxt: %s\ncaffemodel: %s\n",modelTxt.c_str(),modelBin.c_str()) ; &#125; printf("\tload net successfully! Start extract feature\n"); const Mat fprob = extractFeature(probfile, net).clone(); printf("Initialize dp network successfully!\n"); double threshold = 0.6750; //****************************************************************************************** while (1) &#123; //std::cout&lt;&lt;"start pop"&lt;&lt;std::endl; //std::cout&lt;&lt;"queue empty? "&lt;&lt;QTask.empty()&lt;&lt;std::endl; //sleep(1); if (!QTask.empty()) &#123; pthread_mutex_lock(&amp;mutex); CTask it=QTask.front(); printf("deal %s ", it.m_name.c_str()); std::cout&lt;&lt;" ["&lt;&lt;it.m_data.cols&lt;&lt;", "&lt;&lt;it.m_data.rows&lt;&lt;"]"&lt;&lt;std::endl; QTask.pop(); pthread_mutex_unlock(&amp;mutex); int roww = it.m_data.cols/1.6; int rowh = it.m_data.rows/2.2; if (roww &lt; 50 || rowh &lt; 50) &#123; //printf("\timg too small, ignored\n"); //delete it; //printf("\tdelete old prob"); continue; &#125; int wstart = (it.m_data.rows - roww) / 2; int hstart = (it.m_data.cols - rowh) / 2; Mat cutdata = it.m_data(Range(wstart, wstart + roww), Range(hstart, hstart + rowh)); Mat inputdata; resize(cutdata, inputdata, Size(96, 96)); Mat intputBlob = blobFromImage(inputdata, 1, Size(96, 96), Scalar(127, 127, 127)); //********************************************************************************* //**************************extract feature, compute cosine dist and faceRec******* CV_TRACE_REGION("forward"); net.setInput(intputBlob, "data"); Mat fcomp = net.forward("fc1"); double upstair = fcomp.dot(fprob); double downstair1 = sqrt(fprob.dot(fprob)); double downstair2 = sqrt(fcomp.dot(fcomp)); double cosTest = 0.5 + 0.5*upstair / downstair1 / downstair2; if (cosTest &gt;= threshold) &#123; printf("\tcosine dist is %.4f", cosTest); printf("\tsame face\n"); &#125; //delete it; /* CTask *it = &amp;QTask.front(); printf("deal %s\n", it-&gt;m_name.c_str()); //***************************filter small img and resize to 96x96******************* int roww = it-&gt;m_data.cols/1.6; int rowh = it-&gt;m_data.rows/2.2; if (roww &lt; 50 || rowh &lt; 50) &#123; printf("\timg too small, ignored\n"); QTask.pop(); pthread_mutex_unlock(&amp;mutex); delete it; continue; &#125; int wstart = (it-&gt;m_data.rows - roww) / 2; int hstart = (it-&gt;m_data.cols - rowh) / 2; Mat cutdata = it-&gt;m_data(Range(wstart, wstart + roww), Range(hstart, hstart + rowh)); Mat inputdata; resize(cutdata, inputdata, Size(96, 96)); Mat intputBlob = blobFromImage(inputdata, 1, Size(96, 96), Scalar(127, 127, 127)); //********************************************************************************* //**************************extract feature, compute cosine dist and faceRec******* CV_TRACE_REGION("forward"); net.setInput(intputBlob, "data"); Mat fcomp = net.forward("fc1"); double upstair = fcomp.dot(fprob); double downstair1 = sqrt(fprob.dot(fprob)); double downstair2 = sqrt(fcomp.dot(fcomp)); double cosTest = 0.5 + 0.5*upstair / downstair1 / downstair2; printf("\tcosine dist is %.4f", cosTest); if (cosTest &gt;= threshold) &#123; printf("\tsame face"); &#125; QTask.pop(); delete it; */ &#125; &#125;&#125;int main(int argc, char **argv) &#123; //********create a thread for faceRecognization********** //new thread pthread_t thread; int isthread; isthread = pthread_create(&amp;thread, NULL, queWork, NULL); if (isthread != 0) &#123; printf("create thread fail: %s\n", strerror(isthread)); exit(-1); &#125; //******************************************************** pthread_mutex_init (&amp;mutex,NULL); using namespace std; const char* dir_name = "./sample"; struct dirent * filename; // return value for readdir() DIR * dir; // return value for opendir() dir = opendir( dir_name ); if(dir==NULL)&#123; cout&lt;&lt;"open dir error"&lt;&lt;endl; &#125; while( ( filename = readdir(dir) ) != NULL )&#123; struct CTask task; if( strcmp( filename-&gt;d_name , "." ) == 0 ||strcmp( filename-&gt;d_name , "..") == 0 ) continue; string name=filename-&gt;d_name; string path; path.assign("./sample/").append(name); //cout&lt;&lt;path&lt;&lt;endl; task.m_name = name; Mat data=imread(path.c_str()); if (data.empty()) &#123; printf("\t\tCan't read image from the file: %s\n" , path.c_str() ); &#125; task.m_data = data; //cout&lt;&lt;data&lt;&lt;endl; pthread_mutex_lock (&amp;mutex); QTask.push(task); pthread_mutex_unlock(&amp;mutex); cout&lt;&lt;"push "&lt;&lt;name&lt;&lt;" "; cout&lt;&lt;"["&lt;&lt;QTask.front().m_data.rows&lt;&lt;", "&lt;&lt;QTask.front().m_data.cols&lt;&lt;"]"&lt;&lt;endl; sleep(1); &#125; closedir(dir); return 0; &#125;]]></content>
      <categories>
        <category>程序开发</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于LTR的人脸质量评估]]></title>
    <url>%2F2018%2F04%2F14%2F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%9F%BA%E4%BA%8ELTR%E7%9A%84%E4%BA%BA%E8%84%B8%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BC%B0%2F</url>
    <content type="text"><![CDATA[文献来源Face Image Quality Assessment Based on Learning to Rank 显然，人脸识别系统的性能会受到输入的人脸图片质量(光照，姿态，表情，分辨率等)的影响。这一问题在将人脸识别系统应用到实际场景中更为严重，因为实际场景往往是无约束的，捕获的人物也是“不配合”的。虽然很多人脸识别系统有一定的抗干扰能力，研究者仍然认为人脸识别系统在高质量的人脸图片上能表现出更好的性能。 对于不同的人脸识别系统而言，好的图片有着不同的定义。例如，对一个擅长处理遮挡问题的系统，上图中(g)质量比(f)更好，因为(g)分辨率比(f)更好；对一个普通系统，(e)比(f)更好，因为(e)人脸姿态更正。 人脸质量估计assumption假定有两个数据集A、B，作者认为数据集A的图片质量均好于B，数据集A在某一特定识别系统中性能优于数据集B，而对于各自数据集中的图片，其质量得分相差不大，即有如下约束。$$\begin{align}w^Tx_i&gt;w^Tx_j,&amp;&amp;\forall x_i \in A,\forall x_j \in B\w^Tx_i\approx w^Tx_j,&amp;&amp;\forall x_i \in A,\forall x_j \in A\w^Tx_i\approx w^Tx_j,&amp;&amp;\forall x_i \in B,\forall x_j \in B\\end{align}$$上述表达式与Relative Attributes[^1]相同，因而可以用下述凸最优化表达式代替。$$\begin{align}min \;\;&amp;\frac{1}{2}||w||^2+\lambda_1 \sum \xi_{ij}^2+\lambda_2 \sum \eta_{ij}^2+\lambda_3 \sum \gamma_{ij}^2\\text{s.t.}\;\;&amp;w^Tx_i-w^Tx_j\geqslant 1-\xi_{ij},\;\forall x_i \in A,\forall x_j \in B\&amp;|w^Tx_i-w^Tx_j|\leqslant \eta_{ij},\;\;\;\;\;\forall x_i \in A,\forall x_j \in A\&amp;|w^Tx_i-w^Tx_j|\leqslant \gamma_{ij},\;\;\;\;\;\forall x_i \in B,\forall x_j \in B\&amp;\xi_{ij}\geqslant0,\;\eta_{ij}\geqslant0,\;\gamma_{ij}\geqslant0\end{align}$$上述原始问题可采用Newton method[^2]求解得到。 experiment 具体实验流程包括三个环节。 1.预处理–利用人脸检测器检测人脸，并通过仿射变换对人脸进行对其操作 2.抽取人脸特征–包括Gabor, LBP, CNN, Gist, HoG 3.训练权重系数–将不同特征得分进行融合，具体操作为独立训练每种特征权重系数，最后融合所有得分，再进行第二阶段训练。 附录该部分主要介绍Newton法求解原始问题。 SVM对线性SVM，以L2正则化为例，目标函数对应如下：$$\min_{\boldsymbol{w},b} \frac{1}{2}||\boldsymbol{w}||^2+C\sum_{i=1}^{n}\max (0,1-y_i(\boldsymbol{w}^T\boldsymbol{x_i}+b))$$牛顿法迭代即采用$\boldsymbol{w}\leftarrow \boldsymbol{w}-\boldsymbol{\mathcal{H}}^{-1}\boldsymbol{g}$，其中$\boldsymbol{\mathcal{H}}$与$\boldsymbol{g}$分别是目标函数的海塞矩阵与梯度。 设$\boldsymbol{sv}$是支持向量集合$\boldsymbol{sv}={i,y_i(\boldsymbol{w}^T\boldsymbol{x_i}+b)&lt;1}$，进而$$\begin{align}&amp;\boldsymbol{g}:=\boldsymbol{w}+2C\sum_{i\in\boldsymbol{sv}}(\boldsymbol{w}^T\boldsymbol{x_i}+b-y_i)\boldsymbol{x_i}\&amp;\boldsymbol{\mathcal{H}}:=I+2C\sum_{i\in \boldsymbol{sv}}\boldsymbol{x_i}\boldsymbol{x_i}^T\end{align}$$当矩阵维度很大时，计算矩阵$\boldsymbol{\mathcal{H}}^{-1}$将会非常耗时，因而采用linear conjugate gradient是一个很好的选择。该算法的关键之处在于无须显式计算$\boldsymbol{\mathcal{H}}$，只需计算$\boldsymbol{\mathcal{H}}\boldsymbol{s}=\boldsymbol{s}+2C\boldsymbol{X}^T\boldsymbol{D}\boldsymbol{Xs}$对于部分向量$\boldsymbol{s}$即可，其中$\boldsymbol{D}$是对角矩阵，满足$\boldsymbol{D}_{ii}=1,if\;i\in \boldsymbol{sv},0\;otherwise$。 具体算法伪代码如下 RankSVM基于pairwise下，该部分目标函数定于如下$$\begin{align}min \;\;&amp;\frac{1}{2}||w||^2+\lambda_1 \sum \xi_{ij}^2+\lambda_2 \sum \eta_{ij}^2\\text{s.t.}\;\;&amp;w^Tx_i-w^Tx_j\geqslant 1-\xi_{ij},\;\forall x_i \in A,\forall x_j \in B\&amp;|w^Tx_i-w^Tx_j|\leqslant \eta_{ij},\;\;\;\;\;\forall x_i,x_j \in A\;or\;\forall x_i,x_j\in B\&amp;\xi_{ij}\geqslant0,\;\eta_{ij}\geqslant0\end{align}$$对于上式，若将$x_i-x_j$替换成$x_i$将转换为普通SVM，但在制作数据集时将会造成较大运算量。因而，对于i，j属于不同数据集时，我们只是构造一个稀疏矩阵$A_{p\times n}={A_{ki}=1,A_{kj}=-1,if \;\;\text{is higher rank than}\;x_j}$，其中p表示构成比较对的pairwise数量，n表示样本量。于是，采用$AX$替换$X$即可解决构造新数据集问题。 同样，对于i，j来自同一数据集，我们也构造一个稀疏矩阵$B$将匹配对用$+1,-1$标记。进而，正则项$\lambda_1 \sum \xi_{ij}^2+\lambda_2 \sum \eta_{ij}^2$可以用如下表达式替换$$\begin{align}&amp;\lambda_1 \sum \xi_{ij}^2+\lambda_2 \sum \eta_{ij}^2=\sum[ (\boldsymbol{\lambda}\times \boldsymbol{Out_{对应元素平方}})_{\text{矩阵对应元素相乘}}]\&amp;\boldsymbol{\lambda}=\begin{pmatrix}{\boldsymbol{\lambda_1}}\\boldsymbol{\lambda_2}\end{pmatrix}\&amp;\boldsymbol{Out}=\begin{pmatrix}1\0\end{pmatrix}-\begin{pmatrix}\boldsymbol{A}\boldsymbol{X}\boldsymbol{w}\\boldsymbol{B}\boldsymbol{X}\boldsymbol{w}\end{pmatrix},then\;\;\boldsymbol{Out_{1:A}}\leftarrow \max(0,\boldsymbol{Out_{1:A}})\\end{align}$$ [^1]: Relative Attributes[^2]: Efficient Algorithms for Ranking with SVMs]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>人脸识别</tag>
        <tag>人脸质量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-朴素贝叶斯]]></title>
    <url>%2F2018%2F03%2F23%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
    <content type="text"><![CDATA[本系列整理自《统计学习方法》与《机器学习实战》内容。 本章介绍朴素贝叶斯算法及相关python代码实现。 朴素贝叶斯法朴素贝叶斯对条件概率分布做出了条件独立性假设$$\begin{align}P(X=x|Y=c_k)&amp;=P(X^{(1)}=x^{(1)},X^{(2)}=x^{(2)},\dots,X^{(n)}=x^{(n)}|Y=c_k) \&amp;=\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_k)\end{align}$$ 算法描述输入：训练数据集$T={(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)}$，其中$x_i=(x_i^{(1)},x_i^{(2)},\dots,x_i^{(n)})^T$，$x_i^{(j)}$表示第i个样本第j个特征，$x_i^{(j)}\in {a_{j1},a_{j2},\dots,a_{jS_j}}$ 输出：实例x分类 (1)计算先验概率及条件概率$$\begin{align}&amp;P(Y=c_k)=\frac{\sum_{i=1}^NI(y_i=c_k)}{N}\&amp;P(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)}\end{align}$$(2)对于给定的实例，计算$$P(Y=c_k)\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)$$(3)确定实例x的类$c_k$使上式最大 贝叶斯估计上述方法采用极大似然估计确定先验概率$P(Y=c_k)$与条件概率$P(X^{(j)}=a_{jl}|Y=c_k)$，可能会出现索要估计的概率值为0，即某个属性与某各类的组合未在样本数据中出现。 下述采用贝叶斯估计进行修正。 条件概率的贝叶斯估计为$$P(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)+\lambda}{\sum_{i=1}^NI(y_i=c_k)+S_j\lambda}$$其中，$S_j$是第j个特征的取值种类个数 先验概率的贝叶斯估计为$$P(Y=c_k)=\frac{\sum_{i=1}^NI(y_i=c_k)+\lambda}{N+K\lambda}$$其中，$K$表示分类$c_k$的个数。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-knn]]></title>
    <url>%2F2018%2F03%2F23%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-knn%2F</url>
    <content type="text"><![CDATA[本系列整理自《统计学习方法》与《机器学习实战》内容。 本章介绍knn算法及相关python代码实现。 knn算法算法描述输入：训练数据集$T={(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)}$ 输出：实例x所属类别 (1)在给定距离度量下，在训练集$T$中找出与实例x最近邻的k个点，涵盖这k个点的x的邻域记为$N_k(x)$; (2)在$N_k(x)$中根据分类决策规则（如多数表决）决定x的类别$$y=arg \ \max_{c_j}\sum_{x\in N_k(x)}I(y_i=c_j)$$ 代码实现采用线性扫描，即遍历所有样本点计算最近邻k个点，再进行投票。 几个特殊函数tile(a,rep),argsort(),sorted(iterable,cmp,key,reverse),operator.itemgetter()。 1234567891011121314151617181920212223from numpy import *import operatordef classify0(inX, dataSet, labels, k): dataSetSize = dataSet.shape[0] diffMat = tile(inX, (dataSetSize,1)) - dataSet sqDiffMat = diffMat**2 sqDistances = sqDiffMat.sum(axis=1) distances = sqDistances**0.5 sortedDistIndicies = distances.argsort() #返回distances降序排列对应原始索引 classCount=&#123;&#125; for i in range(k): voteIlabel = labels[sortedDistIndicies[i]] classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1 #get(value,default=None)获 #取dict内元素，若不存在，则返回默认值 ## sorted(iterable,cmp,key,reverse) 适用于所有可迭代对象 # key--用于比较的元素，表示iterable中对应哪一个元素 ## b=operator.itemgetter(i) ## b(a)--返回多维数据a索引为i的元素 sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True) ## 等效表达 # sortedClassCount = sorted(classCount.iteritems(),key=lambda x:x[1],reverse=True) return sortedClassCount[0][0] kd树实现k近邻算法，主要考虑如何快速对训练数据扫描以确定最小距离点。普通的线性扫描在面对大规模数据显得尤为耗时。 构造kd树输入：k维空间数据集$T={x_1,x_2,\dots,x_N}$，其中$x_i=(x_i^{(1)},x_i^{(2)},\dots,x_i^{(k)})^T$ 输出：kd树 (1)开始：构造根节点，对应于包含T的k维空间的超矩形区域 ​ 选择$x^{(1)}$为坐标轴，以T中所有实例的$x^{(1)}$坐标的中位数为切分点，将超巨星区域切分为两个子区域，切分由通过切分点且与坐标轴$x^{(1)}$垂直的超平面实现 ​ 由根节点生成深度为1的左右子节点：左子节点对应坐标$x^{(1)}$小于切分点的子区域，左子节点对应坐标$x^{(1)}$大于切分点的子区域。 ​ 将落在切分超平面的实例点保存在根节点 (2)重复：对深度为j的节点，选择$x^{(l)}$为切分坐标轴，$l=j(mod \ k)+1$，余下操作类似(1) (3)直到两个子区域没有实例存在时停止 最近邻搜索输入：已构造的kd树，目标点x 输出：x的最近邻 (1)确定包含x叶节点：从根节点出发，递归向下访问kd树，若目标点x当前维坐标小于切分点，移动到左子节点，否则相反。直到子节点为叶节点 (2)以此叶节点为“当前最近点“ (3)递归向上回退： ​ (a)若该节点距目标点x更小，则更新“当前最近点” ​ (b)当前最近点一定存在于该节点一个子节点对应区域。检查该子结点的父结点的另一个子结点对应的区域是否有更近的点。具体的，检查另一个子结点对应的区域是否与以目标点为球心、以目标点与“当前最近点”间的距离为半径的超球体相交。如果相交，可能在另一个子结点对应的区域内存在距离目标更近的点，移动到另一个子结点。接着，递归的进行最近邻搜索。如果不相交，向上回退。 (4)当回退到根结点时，搜索结束。最后的“当前最近点”即为x的最近邻点。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-极大似然估计与贝叶斯估计]]></title>
    <url>%2F2018%2F03%2F21%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[本文总结了极大似然估计与贝叶斯估计两种参数估计方式。 极大似然估计与贝叶斯估计是统计中两种对模型的参数确定的方法，两种参数估计方法使用不同的思想。 前者来自于频率派，认为参数是固定的，我们要做的事情就是根据已经掌握的数据来估计这个参数；而后者属于贝叶斯派，认为参数也是服从某种概率分布的，已有的数据只是在这种参数的分布下产生的。 主要参考极大似然估计与贝叶斯估计。 目的所谓参数估计，即在当前数据集下，找到一个概率最大的参数即可，即$$arg \ \max \limits_{\theta}p(\theta|D) = arg \ \max \limits_{\theta}\frac{p(D|\theta)p(\theta)}{p(D)} \tag{1}$$ 引例假设一个抛硬币实验，进行了3次得到三组数据{正正反}，设数据集$D= {x_1,x_2,x_3}={1,1,0}$。假设正面的概率为$\rho$，反面向上概率$1-\rho$，即$\theta=\rho$。 极大似然估计由于极大似然估计属于频率派，即认为参数$\theta$是固定存在的，则$p(\theta)$是一个常数，$p(D)=\rho\times\rho\times(1-\rho)$同样可以由已知数据得到。考虑到每个样本相互独立，于是式$1$即转变为求解$$arg \ \max\limits_{\theta}p(D|\theta)=\max \limits_{\theta}\prod_{i=1}^{n}p(x_i|\theta)$$ 贝叶斯估计对贝叶斯派，参数$\theta$存在自己的分布特性，$p(D)$无法直接从已知数据得到，相应的$p(D|\theta)=\rho\times\rho\times(1-\rho)$。于是对于式$1$$$arg \ \max\limits_{\theta}p(D|\theta)=\frac{p(D|\theta)p(\theta)}{\int {p(D|\theta)p(\theta)d\theta}}$$]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-SVM]]></title>
    <url>%2F2018%2F03%2F16%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-svm%2F</url>
    <content type="text"><![CDATA[本系列是Machine Learning-Andrew Ng学习后整理的读书笔记。 本节主要介绍SVM部分知识，由于Ng介绍过为简单，本节整理自周志华《机器学习》对应章节。 最大化几何间隔在样本空间存在许多个超平面，SVM的作用即找到所有超平面中“最好”的那个，通俗点讲即在正负样本“正中间”确定的那个平面。 在样本空间中，划分超平面可通过如下线性方程描述：$$\boldsymbol{w}^T\boldsymbol{x}+b=0$$其中，$\boldsymbol{w}=(w_1,w_2,\dots,w_n)^T$表示超平面法向量，b表示位移项。 任意点到超平面$(\boldsymbol{w},b)$的距离可写作$r=\frac{|w^Tx+b|}{|w|}$ 若超平面$(\boldsymbol{w},b)$能将训练样本正确分类，即对$(x_i,y_i)$，若$y_i=1$，则$\boldsymbol{w}^Tx_i+b&gt;0$；若$y_i=-1$，则$\boldsymbol{w}^Tx_i+b&lt;0$。令$$\begin{cases}\boldsymbol{w}^Tx_i+b\ge+1&amp;y_i=+1;\\boldsymbol{w}^Tx_i+b\le-1&amp;y_i=-1;\end{cases}$$如上图，距离超平面最近的样本点能使上诉不等式成立，这些点即为支持向量（support vector），两个异类支持向量到超平面的距离之和被称为间隔（margin）$$d=\frac{2}{|w|}$$为了找到最大间隔的超平面，即在满足上诉不等式的条件下，使得$d$最大，等效为$$\begin{align}&amp;\min_{w,b}\frac{1}{2}|w|^2\&amp;\text{s.t.}\;y_i(w^Tx_i+b)\ge1,&amp;i=1,2,\dots,m\end{align}\tag{1}$$ 对偶问题对式$1$进行拉格朗日乘子法，得到对偶的拉格朗日函数$$L(\boldsymbol{w},b,\boldsymbol{\alpha})=\frac{1}{2}|\boldsymbol{w}|^2+\sum_{i=1}^{m}\alpha_i(1-y_i(\boldsymbol{w}^Tx_i+b)) \tag{2}$$令$L(\boldsymbol{w},b,\boldsymbol{\alpha})$对$\boldsymbol{w},b$求偏导并置为零，可得到$$\boldsymbol{w}=\sum_{i=1}^{m}\alpha_iy_ix_i\0=\sum_{i=1}^{m}\alpha_iy_i$$将上式代入$2$可消去$w,b$，即可得到$1$对偶问题。$$\begin{align}&amp;L(\boldsymbol{w},b,\boldsymbol{\alpha})=\max_{\alpha}\sum_{i=1}^m\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{i=j}^{m}\alpha_i\alpha_jy_iy_j\boldsymbol{x_i}^T\boldsymbol{x_j}\&amp;s.t.\quad\begin{cases}\sum_{i=1}^{m}\alpha_iy_i=0\\alpha_i\ge0,&amp;i=1,2,\dots,m\end{cases}\end{align}$$ 核函数若样本在原始空间中不存在一个能正确划分类别的超平面，可将样本从原始空间映射到一个更高位的特征空间，使得样本在这个特征空间内线性可分，记这个映射为$\phi$，对应超平面可表示为$\boldsymbol{w}^T\phi(x)+b=0$。 由于高维空间下，直接计算$\phi(x_i)^T\phi(x_j)$较为困难，因此可以采用*核函数来封装该部分计算，即$$k(\boldsymbol{x_i},\boldsymbol{x_j})=\phi(x_i)^T\phi(x_j)$$ 高斯核高斯核有两个主要参数$\mu,\sigma$，高斯核的形式为$$exp(-\frac{|x-\mu|^2}{2\sigma^2})$$其中，$\mu$控制核中心的位置，$\sigma$控制陡峭程度。 在SVM中，若采用高斯核，需要控制的参数只有$\sigma$。 $\sigma$越大，特征变化越平缓，会产生高偏差低方差（更易欠拟合）； $\sigma$越小，特征变化越陡峭，会产生低偏差高方差（更易过拟合）； 软间隔现实任务中往往很难确定合适的核函数使得训练样本在特征空间中线性可分，即便线性可分，也很难判定这个结果不是由于过拟合造成的。 缓解这个问题的一个方法是允许支持向量机在一些样本上出错，引入“软间隔”概念。允许某些样本不满足约束 $y_i(\boldsymbol{ω}^Tx_i+b)\ge1$，优化目标可写成$$\min_{w,b}\frac{1}{2}|\boldsymbol{w}|^2+C\sum_{i=1}^{m}l_{0/1}(y_i(\boldsymbol{ω}^Tx_i+b)-1) \tag{3}$$其中$l_{0/1}$是“0/1损失函数”$$l_{0/1}(z)=\begin{cases}1,&amp;if\;z&lt;0\0,&amp;otherwise\end{cases}$$由于$l_{0/1}$非凸、非连续、数学性质不好，使得式$3$难以求解，因此人们用其他一些函数来代替它，称为“代替函数”。 SVM调参在SVM中，需要调整的参数包括系数$C$，核函数选择，$\sigma$ （如果采用高斯核）。其中$C$可看做logestic regression中$\frac{1}{\lambda}$。因而，在调整$C$时 $C$越大，会产生低偏差高方差（更易过拟合），将会迫使所有样本均满足分类； $C$越小，会产生高偏差低方差（更易欠拟合），允许一些样本不满足分类； 最后，在操作SVM，一般按照下述步骤。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-Tips]]></title>
    <url>%2F2018%2F03%2F16%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-tips%2F</url>
    <content type="text"><![CDATA[本系列是Machine Learning-Andrew Ng学习后整理的读书笔记。 本节主要介绍TPIS部分知识，即如何选择一个算法，如何改进一个算法，如何评估一个算法。 战略方针在面对采用机器学习算法得到的误差较大时，通常要从以下几个方面入手考虑 获取更多训练数据 增加（减少）特征数量 增加多项式特征（$x_1^2,x_2^2,x_1x_2,etc.$） 增加（减少）正则化系数 数据集划分一般情况，为了能够更好验证模型的准确度及其泛化能力，需要将数据划分为三个部分： 训练集（Train set）–用于模型训练，求取最优化参数 交叉验证集（Validation set）–用于测试模型准确度 测试集（Test set）–用于测试模型泛化能力 参数调整在不改变特征数量的情况下，我们需要对参数进行调整以获得更准确的模型。但，凡事都有个度，太小了不好，太大了仍然不好，因此需要有一定的标准来帮助选取最优化的参数。 多项式选取考虑$d$为多项式维数，在不同维数下可以得到不同的模型，进而得到不同模型下的训练代价函数$J_{train}(\theta)$与交叉验证代价函数$J_{cross-validation}(\theta)$，对应曲线如下图。 注意，在计算代价函数时，应忽略正则项影响。 高偏差（High bias）–当多项式次数较低时，模型不能很好拟合训练数据，即出现欠拟合情况。这种情况下，交叉验证集同样会有着较大的误差。 高方差（High variance）–当多项式次数较高时，模型虽然能很好拟合训练数据，但对于新的样本数据，即交叉验证集可能出现较大的误差，即出现过拟合情况。 正则项系数同样，对于正则项系数的选取，也可以做出与上图类似的曲线。具体情况见下图描述，此处不再分析。 数据集大小多数情况下，我们都会认为，模型的训练效果不好是因为训练数据不够充分。于是我们便会疯狂增加数据集，以期望提高模型准确度。但事实并非如此。 学习曲线以训练集大小作为x轴，作出学习曲线，能够有效地帮助我们进行分析。注意，在计算代价函数时，应忽略正则项影响。 高偏差即欠拟合情况下，增大数据量并不能提高模型精度。 当数据集很少的时候，显然训练模型能够充分拟合这些少量数据点，即$J_{train}(\theta)$很小，而交叉验证代价函数$J_{cross-validation}(\theta)$将会很大。 当数据集很大的时候，因为是欠拟合情况，训练集的数据也无法能全部有效拟合，即$J_{train}(\theta)$与$J_{cross-validation}(\theta)$都会很大，并且$J_{train}(\theta)\approx J_{cross-validation}(\theta)$。 高方差即过拟合情况下，增大数据量一定程度上能提高模型精度。 与上诉情况相同，当数据集很少的时候，显然训练模型能够充分拟合这些少量数据点，即$J_{train}(\theta)$很小，而交叉验证代价函数$J_{cross-validation}(\theta)$将会很大。 当数据集很大的时候，因为是过拟合情况，训练集的数据能全部有效拟合，但对于未出现的新样本，模型的准确度可能很差，即$J_{cross-validation}(\theta)$会远大于$J_{train}(\theta)$。但随着数据量的不断增大，训练集中的样本覆盖范围更广（样本范性更强），从而能有效抑制过拟合。 模型评估Ng建议的解决ML问题的方法步骤如下 选取一个能快速实现的简单算法，并在交叉验证集上进行测试 绘制学习曲线用来判断问题原因是高偏差or高方差，以决定采用增加feature，增加数据等方式进行改进 人工检查错误数据并分析总结出错原因，尝试找到错误集合的共同点 单一的准确性指标用来衡量一个模型的好坏远远不够，在遇到偏斜类（skewed classes）问题时，该指标就无法好好工作。 偏斜类问题所谓偏斜类问题，以二分类为例，真实数据绝大部分都属于某一类（不妨设属于第0类概率，99.5%），这样我们可以直接设置一个分类器$y=0$，即可得到99.5%正确率的模型。然而，这个算法真的能表现这个案例么？ 为了能更好评估模型质量，我们引入查准率（Precision）与召回率（Recall）。 查准率与召回率$$查准率=\frac{真值为正且预测为正}{预测为正}=\frac{真值为正且预测为正}{真值为正且预测为正+真值为假但预测为正} \召回率=\frac{真值为正且预测为正}{真值为正}=\frac{真值为正且预测为正}{真值为正且预测为正+真值为正但预测为假}$$ F score用于综合比较有着不同precision(P), recall(R)的不同模型质量。$$F=\frac{2PR}{P+R}$$]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-神经网络]]></title>
    <url>%2F2018%2F03%2F14%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[本系列是Machine Learning-Andrew Ng学习后整理的读书笔记。 本节主要介绍神经网络部分知识。 神经网络神经元作为神经网络基本组成单位，神经元主要有激励信号（输入信号）、权重等组成。 其中$a_1^{(i)},a_2^{(i)},a_3^{(i)}$为第$i$级激励信号，即输入信号$\boldsymbol{x}$。$\theta^{(i)}$为第$i$层神经网络的权重系数。$$z_1^{(2)}=\boldsymbol{\theta}_{10}^{(1)}x_0+\boldsymbol{\theta}_{11}^{(1)}x_1+\boldsymbol{\theta}_{12}^{(1)}x_2+\boldsymbol{\theta}_{13}^{(1)}x_3 \z_2^{(2)}=\boldsymbol{\theta}_{20}^{(1)}x_0+\boldsymbol{\theta}_{21}^{(1)}x_1+\boldsymbol{\theta}_{22}^{(1)}x_2+\boldsymbol{\theta}_{23}^{(1)}x_3 \z_3^{(2)}=\boldsymbol{\theta}_{30}^{(1)}x_0+\boldsymbol{\theta}_{31}^{(1)}x_1+\boldsymbol{\theta}_{32}^{(1)}x_2+\boldsymbol{\theta}_{33}^{(1)}x_3 \a_1^{(2)}=g(z_1^{(2)}) \a_2^{(2)}=g(z_2^{(2)}) \a_3^{(2)}=g(z_3^{(2)})$$整理成向量形式，即$$a^{(l)}=\begin{bmatrix}a_0^{(l)}\a_1^{(l)}\\dots\a_n^{(l)}\end{bmatrix},z^{(l)}=\boldsymbol{\theta}^{(l-1)}a^{(l-1)}$$然而只含一层结构的神经网络，其表达能力有限，只能用来进行线性分析。如下图，单层神经网络可以很好表示AND, OR, NOT等，但是对于XOR却无法表示（非线性不可分）。 代价函数简单的考虑，多输出神经网络即为多分类的逻辑回归。相应的代价函数即为多个分类器代价函数之和。 注意，这里的正则项需剔除$\boldsymbol{\theta}$的常系数对应项。 反向传播算法反向传播算法（Backpropagation Algorithm）是神经网络中用于最小化代价函数的方法。我们的目标是设定最优化权重$\boldsymbol{\theta}$使得代价函数最小，即$\min_{\theta}J(\theta)$。 以上图一个三层网络为例，整个算法流程如下 Back propagation Algorithm 设有5000个样本，每个样本有400个特征。隐含层输入单元为25，输出层单元为10。即$$\boldsymbol{X}=\boldsymbol{X}{5000\times400} \\boldsymbol{a^{(1)}}=\boldsymbol{a}{5000\times (400+1)},\boldsymbol{\theta^{(1)}}=\boldsymbol{\theta}{25\times (400+1)} \\boldsymbol{a^{(2)}}=\boldsymbol{a}{5000\times(25+1)},\boldsymbol{\theta^{(2)}}=\boldsymbol{\theta}{10\times(25+1)} \\boldsymbol{a^{(3)}}=\boldsymbol{a}{5000\times10} \\boldsymbol{y}=\boldsymbol{y}_{5000\times10}$$1.利用前向计算，依次计算$a^{(1)},a^{(2)},\dots,a^{(l)}$，注意，这里除了第$L$层，$a^{(l)}$需在最前端增加一列’1’作为偏差值的系数。 2.计算最后一层的误差$\delta^{(l)}=a^{(l)}-y,dim3=[5000,10]$ 3.依次计算前一层的误差值，$\delta^{(l-1)}=\delta^{(l)}\boldsymbol{\theta}^{(l-1)}.*g’(z^{(l)}),dim2=[5000,26]$，注意，对于中间层，需剔除第一列，即偏差项对应的误差值。 4.计算偏导数（不含正则项），$\Delta^{(l)}=\Delta^{(l)}+(\delta^{(l+1)})^Ta^{(l)}$，注意，这里$\Delta^{(l)}$维度应与$\boldsymbol{\theta}^{(l)}$相同。 5.计算含有正则项的偏导数$$D^{(l)}{i,j}:=\begin{cases}\frac{1}{m}(\Delta^{(l)}{i,j}+\lambda\boldsymbol{\theta}^{(l)}{i,j})&amp;j\neq0\\frac{1}{m}(\Delta^{(l)}{i,j})&amp;j=0\end{cases}$$ 梯度检测梯度检测(Gradient checking)可以确保在反向传播算法中梯度求值的正确性，实际上这里利用了导数的极限概念，即利用下式来计算导数的近似值并与反向传播算法求得的导数进行比较。 随机初始化若对权重参数$\boldsymbol{\theta_{ij}^{(l)}}$做相同初始值，将导致下图中前向运算$a_1^{(2)}=a_2^{(2)}$，从而导致BP计算时$\delta_1^{(2)}=\delta_2^{(2)}$，继而参数更新时，$\boldsymbol{\theta_{ij}^{(l)}}$以相同值进行更新，即整个神经网络都进行了相同的计算。即随机初始化的作用就是打破对称性。 一种有效的随机初始化方式如下 12epsilon_init=0.12;W=rand(L_out,1+L_in)*2*epsilon_init-epsilon_init; 其中$\epsilon_{init}=\frac{\sqrt{6}}{\sqrt{L_{in}+L_{out}}}$，$L_{in}=row_{\theta},L_{out}=column_{\theta}$。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-正则化]]></title>
    <url>%2F2018%2F03%2F10%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%AD%A3%E5%88%99%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本系列是Machine Learning-Andrew Ng学习后整理的读书笔记。 本节主要介绍降低过拟合可能性的一种方式，正则化。 正则化正则化(Regulazation)，作为防止过拟合(Overfitting)的一种手段，在讲解之前，先简单介绍下过拟合。 过拟合与欠拟合引用周志华-《机器学习》的一张图片来解释如下。 对于欠拟合，即训练数据学习不充分，没有学习到训练集的所有特征，即训练结果较差。对于过拟合，即学习过分，将一些训练集中的特性当做整个数据集的共性来处理，即训练结果较好，但实际测试性能很差。 防止过拟合主要有两种途径，即（下图截取自吴恩达《机器学习》讲义） 正则项所谓正则化，即在不减少特征数量与参数$\theta$数量的条件下，通过设置惩罚机制(即降低不必要$\theta$权重)来达到目的，相应的代价函数更新为$$J(\boldsymbol{\theta}):=J(\boldsymbol{\theta})+\lambda \displaystyle\sum_{j=1}^{n}\theta_j^2$$注意，这里$\theta_0$不参与正则化。 梯度下降引入正则项后，相应的梯度下降法修正为 正规方程同样，正规方程也应当被修正 注意，修正后的正规方程中，由于引入了正则项，原始方程中的不可逆情况也被修正了。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-逻辑回归]]></title>
    <url>%2F2018%2F03%2F09%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[本系列是Machine Learning-Andrew Ng学习后整理的读书笔记。 本节主要介绍逻辑回归的内容，由于内容上逻辑回归与线性回归相似性极大，只有假设函数与代价函数不同，因而，对应的正规方程(Normal equation)与梯度下降法(Gradient Descent)不做过多介绍。 逻辑回归由于线性回归的假设表示(Hypothesisi Representation)分布范围不是限定在{0,1}之间，将线性函数的那一套照搬到逻辑回归中来，明显不合适。因而在逻辑回归中，我们利用Sigmoid函数（又称Logistic函数）引入了新的假设表示。$$\begin{cases}h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})=g(\boldsymbol{\hat{\theta}}^T \boldsymbol{X}) \\g(z)=\frac{1}{1+e^{-z}}\end{cases}$$ 代价函数假设函数的修改使得我们无法继续使用线性回归的代价函数，因为继续如此，会导致代价函数起伏不定（不是凸函数，convex function），即存在许多的局部最优解。因而更新后的代价函数结果如下。$$\begin{align}J(\boldsymbol{\hat{\theta}})&amp;=\begin{cases}-\frac{1}{m}\displaystyle\sum_{i=1}^{m}log(h_{\boldsymbol{\hat{\theta}}}(x^{(i)}) &amp;&amp; y=1 \-\frac{1}{m}\displaystyle\sum_{i=1}^{m}log(1-h_{\boldsymbol{\hat{\theta}}}(x^{(i)}) )&amp;&amp; y=0\end{cases}\&amp;=-\frac{1}{m}\displaystyle\sum_{i=1}^{m}[y^{(i)}log(h_{\boldsymbol{\hat{\theta}}}(x^{(i)}))+(1-y^{(i)})log(1-h_{\boldsymbol{\hat{\theta}}}(x^{(i)}))]\end{align}$$介绍至此，关于逻辑回归部分就算完成了。剩余部分与线性回归部分相同，不再重复。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用python给女票每日天气提醒]]></title>
    <url>%2F2018%2F03%2F09%2F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-%E5%88%A9%E7%94%A8python%E7%BB%99%E5%A5%B3%E7%A5%A8%E6%AF%8F%E6%97%A5%E5%A4%A9%E6%B0%94%E6%8F%90%E9%86%92%2F</url>
    <content type="text"><![CDATA[写在前面最近在某博客上看到一篇基于python与阿里云的短信发送脚本，觉得有意思就试着复现出来。 弃坑了，主要是因为阿里云短信服务对短信模板要求太死板了，审核不通过。就算通过也就只能发送一个天气情况，没有任何特色。 晚点玩玩微信接口的itchat吧。 整体思路如下 获取气象网API数据→urllib包→json数据格式更便于操作↓阿里云设置→aliyun_SDK→python版本统一↓每日定时执行→通过Linux脚本语言完成 抓取天气找了老半天，找到了不仅显示实时天气，还有预测功能的稳定免费的气象API接口（疯狂打call中…）。 由于该API支持json与xml两种格式，利用urllib包可以轻松获取对应天气数据。12345678910111213141516# -*- coding:utf-8 -*-import urllibimport jsoncity = u'北碚' #待查询城市city = urllib.parse.quote(city) #这一句很关键....坑太大weather_url = 'http://www.sojson.com/open/api/weather/json.shtml?city=%s' %city#抓取网页信息req = urllib.request.urlopen(weather_url)rs = req.read().decode() #采用utf-8解码#获取当天数据，格式如下#&#123;"date":"04日星期四","sunrise":"07:50","high":"高温 7.0℃","low":"低温 5.0℃",#"sunset":"18:08","aqi":24.0,"fx":"无持续风向","fl":"&lt;3级","type":"小雨",#"notice":"下雨了不要紧，撑伞挡挡就行"&#125;weather_info = json.loads(rs)['forecast'] 短短几行代码完成的工作，中间碰到的坑不少。 1.API接口重要性原始博客提供的API接口已经过时，对应数据已不再更新，于是就在度娘上找了另一个相对比较全面的API。但是在执行到倒数第二步时，解码失败，错误代码 ‘utf-8’ codec can’t decode byte 0x8b in position 1: invalid start byte 百度一圈发现，在提交到服务器的request header中有Accept Encoding : gzip, deflate这一选项，这条信息代表本地可以接收压缩格式的数据，而服务器在处理时就将大文件压缩再发回客户端。即，本地接收的不是完整的json格式，而是压缩后的gzip格式，这一点可以通过request.getheaders查询响应头信息得到。然而如何处理请求头，让它不接受压缩格式，一直没弄明白。最终，通过查找另一个比较合适的API绕过了这个问题。 2.url汉字编码该url输入的城市名通过汉字输入。然而，都知道汉字是不能作为url输入的，需要对其进行编码。在原API文档中作者采用utf-8编码（其实是基于url的utf-8编码），于是就将汉字转码为utf-8后再附上url地址，出现访问失败。提取对应汉字编码显示如下 汉字：北碚utf-8：\xe5\x8c\x97\xe7\xa2\x9arl ： %e5%8c%97%e7%a2%9a 可以发现，url将utf-8中的\x替换为%，这是因为url中不允许出现诸如\,这样的字符。更加详细的url转码文档参考阮一峰的博客 博客简述1.url中汉字若为路径，则为对应utf-8编码相关位置替换为%2.url汉字若为搜索关键字，则用的是操作系统的默认编码3.GET和POST方法的编码，用的是网页的编码4.其余过于复杂，略过 阿里云SDK配置配置个铲铲，短信模板要求太严格，没特色了。想要配置的按着阿里云提供的API接口文档即可完成所有操作。]]></content>
      <categories>
        <category>程序开发</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创立ORM--廖雪峰python笔记]]></title>
    <url>%2F2018%2F03%2F09%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0--%E5%BB%96%E9%9B%AA%E5%B3%B0python%E7%AC%94%E8%AE%B0-%E5%88%9B%E7%AB%8BORM%2F</url>
    <content type="text"><![CDATA[本文是根据廖雪峰Day 3 - 编写ORM实践后整理的学习笔记，主要记录实践过程中遇到的问题，以及对其所涉及到的知识进行提炼与补充。 必备知识mysql数据库数据库（database）即按照数据结构来组织、存储与管理数据的仓库。mysql数据库是一种关系型数据库（RDBMS），建立在关系模型基础上的数据库，其特点是： 数据以表(table)的形式存储在数据库中(database) 表的每列为记录名称所对应的数据域【可以理解为划分类】 表的每行为记录名称【可以理解为具体属性】 一种常见的数据表| name | score | place || —– | —– | —– || Mike | 100 | China || Jane | 88 | US || Mille | 68 | UK | RDBMS术语（这里只罗列一些本文可能涉及到的） 主键(key):主键是唯一的，用来查询数据。即主键的属性值能够唯一定位到一组数据【类似书籍的页码】。 索引：索引可以不唯一，使用索引可以快速访问数据库表中的特定信息【类似书籍的目录】注意121.本文所用到的mysql数据库可以去官网下载，但是该数据库只支持python 3.4版本，若要通过python连接数据库，需要下载pymysql模块。2.本文需要使用到异步aiomysql模块，该模块可能与pymysql模块存在版本不兼容问题。妥善处理方式是，更新aiomysql版本为0.0.7，pymysql版本为0.6.7 sql语法篇幅有限，这里只解释本项目用到的schema.sql相关语句，具体语法可参考w3school SQL教程。12345678910111213141516171819202122232425262728--schema.sql--如果存在awesome数据库，则删除该数据库（drop）drop database if exists awesome; --创建awesome数据库（create database）create database awesome; --选择awesome数据库（use）use awesome;--分配权限给特定用户（grant 权限 on 数据库名.表名 to 用户名@登陆方式 identified by &apos;password&apos;）grant select, insert, update, delete on awesome.* to &apos;www-data&apos;@&apos;localhost&apos; identified by &apos;www-data&apos;; --创建users表并设置具体列属性create table users ( `id` varchar(50) not null, `email` varchar(50) not null, `passwd` varchar(50) not null, `admin` bool not null, `name` varchar(50) not null, `image` varchar(500) not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`) ) engine=innodb default charset=utf8;--括号内最后两句分别为设置主键，设置索引 执行下列命令即可在mysql数据库中创建相应的数据表。1$ mysql -u root -q &lt; shemal.sql ORM说了这么多，这一节是要干嘛？ORM又是什么玩意？ ORM即Object Relational Mapping，全称对象关系映射。当我们需要对数据库进行操作时，势必需要通过连接数据、调用sql语句、执行sql语句等操作，ORM将数据库中的表，字段，行与我们面向对象编程的类及其方法，属性等一一对应，即将该部分操作封装起来，程序猿不需懂得sql语句即可完成对数据库的操作。 编写ORM模块创建连接池利用’aiomysql.create_pool()`创建协程连接池连接数据库。123456789101112131415161718async def create_pool(loop, **kw): &apos;&apos;&apos;创建连接池 &apos;&apos;&apos; logging.info(&apos;create database connection pool...&apos;) global __pool __pool = await aiomysql.create_pool( host=kw.get(&apos;host&apos;, &apos;localhost&apos;), port=kw.get(&apos;port&apos;, 3306), user=kw[&apos;user&apos;], password=kw[&apos;password&apos;], db=kw[&apos;database&apos;], charset=kw.get(&apos;charset&apos;, &apos;utf8&apos;), autocommit=kw.get(&apos;autocommit&apos;, True), maxsize=kw.get(&apos;maxsize&apos;, 10), minsize=kw.get(&apos;minsize&apos;, 1), loop=loop ) 注意1数据库的连接打开后一定要及时关闭 关闭连接池123456async def close_pool(): &apos;&apos;&apos;异步关闭连接池&apos;&apos;&apos; logging.info(&apos;close database connection pool...&apos;) global __pool __pool.close() await __pool.wait_closed() 封装数据库操作指令数据库操作主要包括select, execute(update, insert, delete)。除了select需要返回查询内容，其他命令只需返回一个影响行数，故可以封装为一个execute方法。 select123456789101112131415async def select(sql, args, size=None): &apos;&apos;&apos;此处为选取数据库相关数据操作 &apos;&apos;&apos; log(sql, args) global __pool async with __pool.get() as conn:#从连接池获取一个connect async with conn.cursor(aiomysql.DictCursor) as cur:#获取游标cursor await cur.execute(sql.replace(&apos;?&apos;, &apos;%s&apos;), args or ())#将输入的sql语句中的&apos;？&apos;替换为具体参数args if size: rs = await cur.fetchmany(size) else: rs = await cur.fetchall() logging.info(&apos;rows returned: %s&apos; % len(rs)) return rs execute(update, insert, delete)12345678910111213141516171819async def execute(sql, args, autocommit=True): &apos;&apos;&apos;此处执行数据库删减、增添等修改该操作 &apos;&apos;&apos; log(sql) async with __pool.get() as conn: if not autocommit: await conn.begin() try: async with conn.cursor(aiomysql.DictCursor) as cur: await cur.execute(sql.replace(&apos;?&apos;, &apos;%s&apos;), args) affected = cur.rowcount if not autocommit: await conn.commit() except BaseException as e: if not autocommit: await conn.rollback() raise return affected#返回修改行 自顶向下的设计方案当没有思路时，设想如果有一个现成的ORM框架，该去如何使用呢？123456789101112class Model(object): async def save(self, **kw): passclass User(Model): __table__ = &apos;users&apos; #设定操作数据库表 name = StringField(...) #设定列属性 score = FloatField(...) #设定列属性 passu = User(name=&apos;Mike&apos;, score=98.23)u.save() 也就说当操作某数据库的一个数据库表时，只需创立一个类，并利用继承的方式，从父类中继承相关属性与方法，这样就可以直接完成对数据库的操作。 字段类123456789101112131415161718192021class Field(object): &apos;&apos;&apos;用于标识model每个成员变量的类 name:表名称， column_type:值类型， primary_key：是否主键&apos;&apos;&apos; def __init__(self, name, column_type, primary_key, default): self.name = name self.column_type = column_type self.primary_key = primary_key self.default = default def __str__(self): return &apos;&lt;%s, %s:%s&gt;&apos; % (self.__class__.__name__, self.column_type, self.name)class StringField(Field): def __init__(self, name=None, primary_key=False, default=None, ddl=&apos;varchar(100)&apos;): super().__init__(name, ddl, primary_key, default)class IntegerField(Field): pass... Model类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129class ModelMetaclass(type): def __new__(cls, name, bases, attrs): if name == &apos;Model&apos;: return type.__new__(cls, name, bases, attrs) tableName = attrs.get(&apos;__table__&apos;, None) or name logging.info(&apos;found model: %s (table: %s)&apos; %(name, tableName)) mappings = dict() fields = []#可以理解为列名称 primaryKey = None for k, v in attrs.items(): if isinstance(v, Field): logging.info(&apos; found mapping: %s ==&gt; %s&apos; %(k, v)) mappings[k] = v if v.primary_key:#判断主键并记录 if primaryKey: raise RuntimeError(&apos;Duplicate primary key for field: %s&apos; %k) primaryKey = k#记录主键 else: fields.append(k) if not primaryKey: raise RuntimeError(&apos;Primary key not found.&apos;) for k in mappings.keys(): attrs.pop(k)#删除attrs里属性，防止与实例属性冲突 escaped_fields = list(map(lambda f: &apos; %s &apos; %f, fields)) attrs[&apos;__mappings__&apos;] = mappings # 保存属性和列的映射关系 attrs[&apos;__table__&apos;] = tableName attrs[&apos;__primary_key__&apos;] = primaryKey # 主键属性名 attrs[&apos;__fields__&apos;] = fields # 除主键外的属性名 attrs[&apos;__select__&apos;] = &apos;select `%s`, %s from `%s`&apos; % (primaryKey, &apos;, &apos;.join(escaped_fields), tableName) attrs[&apos;__insert__&apos;] = &apos;insert into `%s` (%s, `%s`) values (%s)&apos; % ( tableName, &apos;, &apos;.join(escaped_fields), primaryKey, create_args_string(len(escaped_fields) + 1)) attrs[&apos;__update__&apos;] = &apos;update `%s` set %s where `%s`=?&apos; % ( tableName, &apos;, &apos;.join(map(lambda f: &apos;`%s`=?&apos; % (mappings.get(f).name or f), fields)), primaryKey) attrs[&apos;__delete__&apos;] = &apos;delete from `%s` where `%s`=?&apos; % (tableName, primaryKey) return type.__new__(cls, name, bases, attrs)#------------------------------------------------------------------class Model(dict, metaclass=ModelMetaclass): def __init__(self, **kw): super(Model, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r&quot;&apos;Model&apos; object has no attribute &apos;%s&apos;&quot; % key) def __setattr__(self, key, value): self[key] = value def getValue(self, key): return getattr(self, key, None) def getValueOrDefault(self, key): value = getattr(self, key, None) if value is None: field = self.__mappings__[key] if field.default is not None: value = field.default() if callable(field.default) else field.default#callable(obj)判断对象是否可调用 logging.debug(&apos;using default value for %s: %s&apos; %(key, str(value))) setattr(self, key, value) return value @classmethod async def findAll(cls, where=None, args=None, **kw): &apos;find objects by where clause&apos; sql = [cls.__select__] if where: sql.append(&apos;where&apos;) sql.append(where) if args is None: args = [] orderBy = kw.get(&apos;orderBy&apos;, None) if orderBy: sql.append(&apos;order by&apos;) sql.append(orderBy) limit = kw.get(&apos;limit&apos;, None) if limit is not None: sql.append(&apos;limit&apos;) if isinstance(limit, int): sql.append(&apos;?&apos;) args.append(limit) elif isinstance(limit, tuple) and len(limit) == 2: sql.append(&apos;?, ?&apos;) args.extend(limit) else: raise ValueError(&apos;Invalid limit value: %s&apos; % str(limit)) rs = await select(&apos; &apos;.join(sql), args) return [cls(**r) for r in rs] @classmethod async def findNumber(cls, selectField, where=None, args=None): &apos;find number by select and where&apos; sql = [&apos;select %s _num_ from `%s`&apos; %(selectField, cls.__table__)] if where: sql.append(&apos;where&apos;) sql.append(where) rs = await select(&apos; &apos;.join(sql), args, 1) if len(rs) == 0: return None return rs[0][&apos;_num_&apos;] @classmethod async def find(cls, pk): &apos;find object by primary key&apos; rs = await select(&apos;%s where `%s`=?&apos; %(cls.__select__, cls.__primary_key__), [pk], 1) if len(rs) == 0: return None return cls(**rs[0]) async def save(self): args = list(map(self.getValueOrDefault, self.__fields__)) args.append(self.getValueOrDefault(self.__primary_key__)) rows = await execute(self.__insert__, args) if rows != 1: logging.warn(&apos;failed to insert record: affected rows: %s&apos; % rows) async def update(self): args = list(map(self.getValue, self.__fields__)) args.append(self.getValue(self.__primary_key__)) rows = await execute(self.__update__, args) if rows != 1: logging.warn(&apos;failed to update by primary key: affected rows: %s&apos; %rows) async def remove(self): args = [self.getValue(self.__primary_key__)] rows = await execute(self.__delete__, args) if rows != 1: logging.warn(&apos;failed to remove by primary key: affected rows: %s&apos; % rows) 关于元类暂时没有理解透彻，之后再做补充。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础-线性回归]]></title>
    <url>%2F2018%2F03%2F08%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[本系列是Machine Learning-Andrew Ng学习后整理的读书笔记。 本节主要介绍线性回归以及线性回归中中的参数$\theta$求解所采用的正规方程(Normal equation)与梯度下降法(Gradient Descent)。 线性回归标准的线性模型形式如下，其中$\boldsymbol{x}=(x_1,x_2,\dotsc,x_m)$，$\boldsymbol{\theta}=(\theta_1,\theta_2,\dotsc,\theta_m)$$$h(\boldsymbol{x})=\theta_1x_1+\theta_2x_2+\dotsc+\theta_mx_m+b \tag{1}$$注意，多项式回归(Polynomial Regression)也是线性回归的一种形式。$$h(\boldsymbol{x})=\theta_1x_1+\theta_2x_2^2+\dotsc+\theta_m\sqrt{x_m}+b$$在上式中，将$x_2^2,\sqrt{x_n}$替换成$x_2,x_m$即可得到式$1$的形式。 当然，若令$x_0=1$，则式$1$可进一步化简为$$h(\boldsymbol{x})= \boldsymbol{X}\boldsymbol{\hat{\theta}}^T \tag{2}$$其中$$\boldsymbol{\hat{\theta}}=(\theta_1,\theta_2,\dotsc,\theta_m,b)$$ $$\boldsymbol{X}=\begin{pmatrix}\boldsymbol{x}_1^T &amp; 1 \\boldsymbol{x}_2^T &amp; 1 \\vdots &amp; \vdots \\boldsymbol{x}_m^T &amp; 1\end{pmatrix}$$ 代价函数为了衡量回归模型的准确性，定义一种代价函数(cost funciton)来表示测试结果与真实结果之间的误差。常见的代价函数$J(\theta)$如下$$J(\boldsymbol{\theta})=\frac{1}{2m}\displaystyle\sum_{i= 1}^{m}(h_\boldsymbol{\theta}(\boldsymbol{x})-\boldsymbol{y})^2 \tag{3}$$回归模型约精确，上述代价函数的值也就越小。因而，求解参数$\boldsymbol{\theta}$最优解即求$$\boldsymbol{\theta}^*=\min \limits_{\boldsymbol{\theta}\in \mathbb{R}}J(\boldsymbol{\theta}) \tag{4}$$ 正规方程将$2$式代入$4$式，则有$$\boldsymbol{\hat{\theta}}^*=\min \limits_{\boldsymbol{\hat{\theta}}\in \mathbb{R}}(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\hat{\theta}}^T)^T(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\hat{\theta}}^T)$$为了求$J(\hat{\theta})​$极小值，对$\hat{\theta}​$求导得到$$\frac{\partial J(\boldsymbol{\hat{\theta}})}{\partial \boldsymbol{\hat{\theta}}}=2\boldsymbol{X}^T(\boldsymbol{X}\boldsymbol{\hat{\theta}}-\boldsymbol{y})$$ 进而得到$$\boldsymbol{\hat{\theta}}^*=(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y} \tag{5}$$ 注意对于式$5$，显然若矩阵$\boldsymbol{X}^T\boldsymbol{X}$不可逆，则上式即不成立，而出现上述情况的可能原因主要有两种 1.各个特征之间不独立，相关联，如$x_1=米,x_2=公里$； 2.特征数量大于所给训练样本数。 (批量)梯度下降梯度下降算法((Batch) Gradient Descent)，即先定下一组预设参数$\boldsymbol{\hat{\theta}}$，通常可以是随机生成的，不断微调$h(\boldsymbol{\hat{\theta}})$的参数直到达到代价$J(\boldsymbol{\hat{\theta}})$的局部最小值（Local Minimum）。其中，$\boldsymbol{\hat{\theta}}$的更新公式如下$$\boldsymbol{\hat{\theta}}:=\boldsymbol{\hat{\theta}}-\alpha \frac{\partial}{\partial{\boldsymbol{\hat{\theta}}}}J(\boldsymbol{\hat{\theta}}) \tag{6}$$注意，每个$\theta$必须是同步替换，即待所有$\theta$都迭代完毕后，再将新的$\boldsymbol{\hat{\theta}}$代入式$2$中。 对于当前代价函数，$\theta_i$更新公式如下$$\theta_j :=\theta_j -\alpha \frac{1}{m}\sum_{i=0}^{m}(h_\boldsymbol{\hat{\theta}}(x^{(i)})-y^{(i)})x_j^{(i)} \tag{7}$$ 向量化为了加速程序运算，避免使用for循环，可将式$7$整合为向量形式$\boldsymbol{\hat{\theta}}:=\boldsymbol{\hat{\theta}}-\alpha \frac{1}{m}\boldsymbol{\beta}$。注意到$$\begin{align}\sum_{i=1}^{m}(h_\boldsymbol{\hat{\theta}}(x^{(i)})-y^{(i)})x_j^{(i)} &amp; =(h(x^{(1)})-y^{(1)})*x_j^{(1)}+(h(x^{(2)})-y^{(2)})x_j^{(2)}+… \ &amp; =((h(x^{(1)})-y^{(1)}),(h(x^{(2)})-y^{(2)}),…)(x_j^{(1)},x_j^{(2)},…)^T \ &amp;=(h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y})^T\boldsymbol{x_j} = \boldsymbol{x_j}^T(h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y}) \end{align}$$其中$h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y}$与$\boldsymbol{x_j}$都是列向量。$\boldsymbol{x_j}$表示第$j$个属性的$m$个样本值。 即$$\boldsymbol{\beta}=\begin{pmatrix} \boldsymbol{x_1}^T(h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y}) \ \boldsymbol{x_2}^T(h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y}) \\vdots \ \boldsymbol{x_n}^T(h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y})\end{pmatrix}=\begin{pmatrix} \boldsymbol{x_1}&amp;\boldsymbol{x_2}&amp;\dots &amp;\boldsymbol{x_n}\end{pmatrix}^T(h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y})=\boldsymbol{X}^T(h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y})$$因而，式$7$向量化如下$$\boldsymbol{\hat{\theta}}:=\boldsymbol{\hat{\theta}}-\alpha \frac{1}{m}\boldsymbol{X}^T(h_{\boldsymbol{\hat{\theta}}}(\boldsymbol{X})-\boldsymbol{y})$$ 特征缩放即特征归一化处理，为了加速代价函数的收敛速度，应使得每个特征值缩放到大致相同的范围内。 常见的缩放范围是$-1\sim 1$，具体缩放方式$$x=\frac{x-\mu}{s}$$其中，$\mu$是均值，$s$是标准差。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gabor滤波器]]></title>
    <url>%2F2018%2F03%2F06%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Gabor%E6%BB%A4%E6%B3%A2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[本文主要介绍Gabor核相关知识，以及其在图像处理上的应用。 本文主要考虑提取Gabor特征用于人脸检测。 Gabor核一维Gabor核一维Gabor核由一个高斯核与一个复数波乘积定义： $$\begin{equation}Gabor(t) = ke^{i\theta}w(at)s(t)\tag{1}\end{equation}$$ 其中，$$\begin{cases}w(t) = e^{-\pi t^2}&amp; \quad \text {高斯核} \s(t)=e^{i(2\pi f_0 t)}&amp; \quad \text {复数核}\end{cases}$$这里$f_0$是复数波$s(t)$的频率。 代入式$1$得到$$Gabor(t) = kw(at)[cos(2\pi f_0 t+\theta)+i\cdot sin(2\pi f_0 t+\theta)]$$从上式可以看出，Gabor核可以按实部和虚部划分为实核和虚核。多数情况下，只需选用Gabor核的实数部分即可。$$\begin{cases}Gabor_{real}(t) = w(at)cos(2\pi f_0 t+\theta) \tag{2} \ \Gabor_{imag}(t) = w(at)sin(2\pi f_0 t+\theta)\end{cases}$$ 傅里叶变换对式$1$进行傅里叶变换，得到频域下的Gabor核$$\begin{align}Gabor(f) &amp;= ke^{i\theta}\int_{-\infty}^{+\infty}e^{-i2\pi ft}w(at)s(t)dt\&amp; =ke^{i\theta}\int_{-\infty}^{+\infty}e^{-i2\pi (f-f_0)t}w(at)dt\&amp;=\frac{k}{a}\cdot e^{i\theta}\cdot w(\frac{f-f_0}{a})\end{align}$$基于上式，Gabor核相当于在频域应用了一个高斯核窗口，从而实现过滤$f_0$频率领域范围内的信号。 二维Gabor核同一维Gabor核一样，二维Gabor核也是由二维高斯函数与二维复数波组合得到。 二维复数波二维复数波的定义如下，由于初始相位$\phi$对Gabor核影响不大，因此常常可以省略。$$s(x,y)=exp(i(2\pi (u_0x+v_0y)+\phi))$$ 二维高斯函数二维高斯函数定于如下：$$w(x,y,\sigma _x,\sigma _y)=Kexp(-\pi (\frac{(x-x_0)^2}{\sigma_x^2}+\frac{(y-y_0)^2}{\sigma_y^2})) \tag{3}$$其中，$\sigma_x,\sigma_y$分别是两个方向上的尺度参数，$(x_0,y_0)$为高斯函数的中心点，$K$为常数。 若考虑高斯函数的旋转（顺时针）$$\begin{cases}(x-x_0)_r=(x-x_0)cos\theta+(y-y_0)sin\theta\(y-y_0)_r=-(x-x_0)sin\theta+(y-y_0)cos\theta\end{cases}$$代入$3$式可以得到，加入旋转参数后的二维高斯函数为： $w(x,y,\sigma _x,\sigma _y)=Kexp(-\pi (\frac{(x-x_0)_r^2}{\sigma_x^2}+\frac{(y-y_0)_r^2}{\sigma_y^2})) \tag{4}$]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-图]]></title>
    <url>%2F2018%2F03%2F05%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[本篇文章整理《数据结构（C++语言版）》关于二叉树这种线性结构知识点。 图图的描述比较特殊的两种图（1）欧拉环路：经过所有的边有且仅有一次的环路。（2）哈密尔顿环路经过所有点有且仅有一次的环路。邻接矩阵与关联矩阵图可以通过矩阵形式进行描述。（1）邻接矩阵：描述顶点之间相互邻接关系。（n x n格式，n个顶点）（2）关联矩阵：描述顶点与边之间的关联关系。（n x e格式，n个顶点，e条边） 图结构的实现图结构接口定义代码如下12345678910111213template &lt;typename Tv, typename Te&gt;class Graph &#123; private: void reset() &#123; //所有顶点，边的辅助信息复位 for (int i = 0; i &lt; n; i++) &#123; //顶点 status(i) = UNDISCOVERED; dTime(i) = fTime(i) = -1; parent(i) = -1; priority(i) = INT_MAX; for (int j = 0; j &lt; n; j++) //边 if (exists(i, j)) status(i, j) = UNDETERMINED; &#125; &#125;public: /*...顶点操作、边操作，图算法&#125; 顶点类型的实现代码如下12345678910111213typedef enum &#123; UNDISCOVERED, DISCOVERED, VISITED &#125; VStatus;template &lt;typename Tv&gt; struct Vertex &#123; //顶点对象（并未严格封装） Tv data; int inDegree, outDegree; //数据、出入度 VStatus status; //（如上三种）状态 int dTime, fTime; //时间标签 int parent; //在遍历树中的父节点 int priority; //在遍历树中的优先级（最短通路，极短跨边等） Vertex(Tv const &amp; d): //构造函数，初始化列表，构造新顶点 data(d), inDegree(0), outDegree(0), status(UNDISCOVERED), dTime(-1), fTime(-1), parent(-1), priority(INT_MAX) &#123;&#125;&#125; TIPS:关于typedef与define1.使用方式宏定义： #difine int_PTR int //将int 用int_PTR代替typedef： typedef int int_ptr //将int 用int_ptr代替2.编译处理宏定义是预处理指令，在编译预处理时进行简单的替换，不做正确性检查；typedef是在编译时处理的。const int_ptr p; //相当于const int p,把指针锁住，即p不能改变，但其指向的内容可变const int_PTR p; //仅仅将其替换掉，相当于const( int p)，把指针指向对象锁住，即p指向的内容不能改变 边类型的实现代码如下12345678910typedef enum&#123;UNDETERMINED, TREE, CROSS, FORWARD， BACKWARD&#125; EStatus;template &lt;typename Te&gt;struct Edge &#123; //边对象（并未严格封装） Te data; //数据 int weight; //权重 EStatus status; //类型 Edge(Te const&amp; d, int w) : //构造函数，初始化列表，构造新边 data(d), weigth(w), status(UNDETERMINED) &#123;&#125;&#125; 基于邻接矩阵实现图结构首先将顶点集与边集兑现为对应的数据结构。对于边集而言，这里套用了两层Vector结构，继承了Vector中重载的[ ]操作符用法。第一层，将以某个顶点为中心的所有关联边整合（行向量），随后再整合为列向量。因而E[i] [j]即为邻接矩阵。代码如下123456789101112131415template&lt;typename Tv, typename Te&gt;class GraphMatrix : public Graph&lt;Tv, Te&gt; &#123;private: Vector&lt; Vertex&lt;Tv&gt; &gt; V; //顶点集 Vector&lt; Vector&lt; Edge&lt;Te&gt;* &gt; &gt; E; //边集public:/*...操作接口...*/ GraphMatrix() &#123;n = e = 0; &#125; ~GraphMatrix() &#123; //析构 for (int j=0; j&lt;n; j++) for (int k=0;k&lt;n;k++) //基于Vector模板类，可以调用Vecotr封装的[ ]寻秩操作符 delete E[j] [k]; //清除所有动态申请的边记录 &#125;&#125; 相关算法顶点操作1.枚举当前顶点所有邻接顶点即从当前顶点i开始，依次判断其余顶点j与顶点i之间是否有关联边（i, j）存在。12345678int nextNbr(int i, int j) &#123; //若已枚举至邻居j，则转向下一个邻居 while( (-1 &lt; j) &amp;&amp; !exits(i, --j) ); //逆序查找 return j;&#125;int firstNbr(int i)&#123; return nextNbr(i, n);&#125; 2.顶点插入插入一个新顶点，需要对邻接矩阵进行扩充。①表示增加每个顶点到新顶点的边集合（初始化为NULL）②表示新顶点到每个顶点的边集合（初始化为NULL）③④表示对边集合与顶点集合扩充。123456int insert(Tv const &amp; vertex)&#123; //插入顶点，返回编号 for(int j = 0; j &lt; n; j++) E[j].insert(NULL); //① n++; //增大矩阵列数 E.insert( Vector&lt; Edge&lt;Te&gt;* &gt;(n, n, NULL) ); //②③ return V.insert( Vertex&lt;Tv&gt; (vertex) ); //④&#125; 3.顶点删除123456789101112131415161718Tv remove(int i) &#123; //删除顶点及其关联边，返回该顶点信息 for(int j = 0; j &lt; n; j++) &#123;//删除关联矩阵中第i行（删除所有出边） if (exists(i, j)) &#123; delete E[i][j]; V[j].inDegree--; &#125; &#125; E.remove(i); //删除第i行 for(int j = 0; j &lt; n; j++) &#123;//删除关联矩阵第i列（删除所有入边） if (exists(j, i)) &#123; delete E[j][i]; V[j].outDegree--; &#125; &#125; Tv vBak = vertex(i); //备份顶点i的信息 V.remove(i); return vBak;&#125; 广度优先遍历以当前顶点为中心，遍历其所有邻接点。再以每个邻接点为中心，遍历其所有尚未访问的邻接点。该算法的实现与树的层次遍历类似，或者说，树的层次遍历是图的广度优先遍历的一种特殊情况。具体算法中，每个顶点共设置三种状态{UNDISCOVERED, DISCOVERED, VISITED}分别表示未被发现、被发现、被访问，每条边共设置三种状态{UNDETERMINED, CROSS, TREE}分别表示未被发现、被访问、不访问。12345678910111213141516template &lt;typename Tv, typename Te&gt;void Graph&lt;Tv, Te&gt;::BFS(int v, int &amp; clock)&#123; Queue&lt;int&gt; Q; status(v) = DISCOVERED; Q.enqueue(v); while( !Q.empty() ) &#123; int v = Q.dequeue(); dTime(v) = ++clock; //取出队首顶点v for(int u = firstNbr(v); -1 &lt; u; u = nextNbr(v, u)) &#123; //找寻当前顶点v的邻接点u if(UNDISCOVERED == status(u)) &#123; //若u未被发现 status(u) = DISCOVERED; Q.enqueue(u); //发现该节点并入队 status(v, u) = TREE; parent(u) =v; //访问该关联边 &#125; else //若u已被发现（已入队）或已被访问 status(v, u) = CROSS; //设置该关联边为不访问状态 &#125; status(v) = VISITED; &#125;&#125; 变式：若该图中包含不只一个连通域的情形，采用BFS搜索，只需逐一检查每个顶点，若状态为UNDISCOVERED，则对当前顶点启动BFS搜索。 深度优先遍历起始于顶点s，在其未被访问的邻接点中任选其一，递归执行。设父节点为v，其递归执行的子节点u。①若u的邻接节点s状态为UNDISCOVERED，则继续递归执行； j的邻居包含g么？？？？？？？？？ ②若状态为DISCOVERED（表明该节点s已置入遍历树中），则将边（u，s）设置为BACKWARD（该边不置入遍历树），回退到其父节点u； ③若状态为VISITED，则比较节点u与节点s的发现时间（dTime）标签。若u标签更小，即u更早被发现，则标记边（u，s）为FORWARD；否则，标记为CROSS。代码如下1234567891011121314template&lt;typename Tv, typename Te&gt;void Graph&lt;Tv, Te&gt;::DFS(int v, int &amp; clock) &#123; dTime(v) = ++clock; status(v) = DISCOVERED; for(int u = firstNbr(v); -1 &lt; u; u = nextNbr(v, u)) &#123; switch( status(u) ) &#123; case UNDISCOVERED: //u尚未发现，支撑数可在u点进行拓展 status(v, u) = TREE; parent(u) =v; DFS(u, clock); break; //在u点递归 case DISCOVERED: //u已被发现 status(v, u) = BACKWARD; break; default: //u已访问完毕 status(v, u) = dTime(v) &lt; dTime(u) ? FORWARD : CROSS; break; &#125; status(v) = VISITED; fTime(v) = ++clock; //记录节点访问完毕的时钟&#125; 嵌套引理1.顶点活动期active[u] = ( dTime[u], fTime[u] )2.给定有向图G=（V, E）及其任一DFS森林，则active[u] ⊆ active[v]，则u是v的后代；active[u] ⊇ active[v]，则u是v的祖先；active[u] ∩ active[v] = ∅，则u与v无亲缘关系。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-二叉树]]></title>
    <url>%2F2018%2F03%2F05%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[本篇文章整理《数据结构（C++语言版）》关于二叉树这种线性结构知识点。 二叉树关于二叉树的概念，图论中有详细说明，这里不过多解释。结构上而言，二叉树与列表类似。可以将二叉树理解为半线性结构。 二叉树节点与列表节点的前驱后继相似，二叉树也有祖先parent,左孩子lChild,右孩子rChild以及存储具体值的data。因此，二叉树节点BinNode实现如下：1234567891011121314151617181920212223#define BinNodePosi(T) BinNode&lt;T&gt;*template&lt;typename T&gt;struct BinNode&lt;T&gt; &#123; T data; //数值 BinNodePosi(T) parent; BinNodePosi(T) lChild; BinNodePosi(T) rChild; //祖先，左右孩子 int height; //高度//构造函数，列表初始化 BinNode() : parent(NULL), lChild(NULL), rChild(NULL) &#123;&#125; BinNode(T e, BinNodePosi(T) p=NULL, BinNodePosi(T) lc=NULL, BinNodePosi(T) rc=NULL, int h=0) : data(e), parent(p), lChild(lc), rChild(rc), height(h) &#123;&#125;//操作接口 int size(); //统计当前节点后代总数，亦即以其为根的子树的规模 BinNodePosi(T) insertAsLC ( T const&amp; ); //作为当前节点的左孩子插入新节点 BinNodePosi(T) insertAsRC ( T const&amp; ); //作为当前节点的右孩子插入新节点 BinNodePosi(T) succ(); //取当前节点的直接后继 template &lt;typename VST&gt; void travLevel ( VST&amp; ); //子树层次遍历 template &lt;typename VST&gt; void travPre ( VST&amp; ); //子树先序遍历 template &lt;typename VST&gt; void travIn ( VST&amp; ); //子树中序遍历 template &lt;typename VST&gt; void travPost ( VST&amp; ); //子树后序遍历&#125; 以插入左孩子insertAsLC为例，介绍如何插入一个新的二叉树节点。通过调用BinNode节点中的构造函数，新建一个BinNode节点，其中{data=e, parent=this, lChild=NULL, rChild=NULL}。随后，再将当前节点的左孩子指向新建的节点即可。具体代码如下：1234template &lt;typename T&gt; BinNodePosi(T) insertAsLC(T const&amp; e) &#123; return lChild = new BinNode(e, this);&#125; 遍历算法先序遍历先序遍历，即先访问根节点，再依次访问左子树与右子树。算法1：借助栈结构。访问当前根节点，随后先将其右子树压入栈中，再将左子树压入栈中，随后弹出栈顶元素（左孩子），重复上述操作。代码实现如下：1234567891011//version 1template&lt;typename T, typename VST&gt;void travPre_I1(BinNodePosi(T) x, VST &amp; visit) &#123; stack&lt;BinNodePosi(T)&gt; S; //辅助栈 if(x) S.push(x); //根节点入栈 while(!S.empty()) &#123; x = S.pop(); visit( x-&gt;data ); if( HasRChild(*x) ) S.push(x-&gt;rChild); if( HasLChild(*x) ) S.push(x-&gt;lChild); &#125;&#125; 算法2（推广至中序遍历甚至后序遍历等）：如下图所示，整个二叉树遍历可以看做是一个简化的左子树链。对于每个节点而言，先扫描当前节点，继而扫描其左孩子，当所有左子树的左孩子扫描完成后，以当前节点的右孩子当做新的左子树链，重复上述操作。代码实现：12345678910111213141516171819202122232425//version 2//左子树链的实现template&lt;typename T, typename VST&gt;static void visitAlongLeftBranch(BinNodePosi(T) x, VST &amp; visit, stack&lt;BinNodePosi(T)&gt; &amp; S) &#123; while(x) &#123; visit(x-&gt;data); S.push(x-&gt;rChild); //右孩子入栈 x = x-&gt;lChild; &#125;&#125;//主算法实现template&lt;typename T, typename VST&gt;void travPre_I2(BinNodePosi(T) x, VST &amp; visit) &#123; stack&lt;BinNodePosi(T) S; S.push(x); //当前节点入栈 while(!S.empty()) &#123; visitAlongLfetBranch(x, visit, S); //左子树链中所有左孩子遍历完成后，进入最后一个右孩子重新构造左子树链，重新遍历 x = S.pop(); &#125;&#125; 中序遍历中序遍历，即依次访问左孩子，当前节点，右孩子。算法：如下图所示，节点优先权会依次传递给左子树链最后一个左孩子，随后，访问其右子树，重复操作。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-栈与队列]]></title>
    <url>%2F2018%2F03%2F05%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[本篇文章整理《数据结构（C++语言版）》关于栈与队列这种线性结构知识点。 栈后进先出（LIFO）是栈这种结构最大的特点。对栈而言，只有一端的可访问称作，顶端top。栈也是一种线性结构，即满足逻辑地址连续，故可直接基于向量或列表派生。12345678//基于vector结构的栈初始化template&lt;typename T&gt;class Stack: public Vector&lt;T&gt;&#123;public: void push(T const&amp; e) &#123; insert( size(), e);&#125; //入栈，等效于作为向量末元素插入 T pop() &#123; return remove( size() -1); &#125; //出栈，等效于删除向量末元素 T&amp; top() &#123; return ( *this ) [ size() - 1 ]; &#125; //取顶，直接返回向量的末元素&#125;； 栈应用基于栈结构的应用，就是要充分利用其后进先出LIFO的特性。 括号匹配解决问题：判断一个只含括号的表达式是否匹配。算法：从表达式左侧开始扫描，当扫描到左括号(则压入栈中，若扫描到右括号)则弹出栈顶元素，继续扫描下去。当且仅当最后扫描完成时，栈类所有左括号(均已弹出，栈为空栈时该表达式括号匹配。代码实现123456789bool paren( char exp[], int lo, int hi ) &#123; //exp[lo, hi) Stack&lt;char&gt; s; for(int i=lo; i &lt; hi; i++)&#123; if( '(' == exp[i] ) s.push(exp[i]); //若左括号，入栈 else if( !s.empty() ) s.pop(); //若右括号，且栈非空，弹出栈顶 else return false; //若括号表达式未扫描结束，栈已空，则不匹配 &#125; return s.empty();&#125; TIPS:字符串与字符数组字符串以空字符\0结尾，用来标记字符串的结尾。char dog[4] = {‘a’, ‘b’, ‘c’, ‘d’}; //不是字符串，是char数组char cat[4] = {‘a’, ‘b’, ‘c’, ‘\0’}; //是字符串，也是char数组另一种操作方法是通过双引号声明字符串，若声明长度比实际长度长，则空字符将自动补全到实际长度之后。char bird[5] = “abc”; //实际为 abc\0\0char bird[] = “abc”; //编译器自己判断字符串长度 栈混洗甄别解决问题：将栈A中的元素通过栈S转移入栈B中。对元素的移入移出操作只允许以入栈出栈方式。进而判断栈B中元素序列是否是一种栈混洗。算法：不妨设栈A的元素为升序排列。对栈B中第i个元素，当其从栈S弹出前，S栈顶端以下元素按降序排列。即，若栈S顶元素小于B[i]，则依次将A中元素入栈；若栈S顶元素等于B[i]，则S出栈，继续判断B[i+1]；若栈S顶元素大于B[i]，则不是栈混洗。该算法的一个典型应用场景为火车调度问题。代码实现1234567891011121314151617181920212223/*判断栈B中序列是否为一种栈混洗为了简化问题，栈A、B元素确定，因此可以通过数组等方式实现。/*int A = 1;int B[] = &#123;2, 3, 1, 4, 5&#125;;bool Stackverfi(int A, const int* array_B)&#123; Stack&lt;int&gt; S; for(int i = 0; i &lt; 5; i++)&#123; while( S.top() &lt; B[i] )&#123; S.push(A++); std::cout &lt;&lt; "push\n"; &#125; if( S.top() == B[i] )&#123; S.pop(); std::cout &lt;&lt; "pop\n"; &#125; else&#123; std::cout &lt;&lt; "NO!!!"; return false; &#125; &#125;&#125; 中缀表达式算法：对于一个正确的算数表达式，先准备两个栈A，B分别用于存储运算符和运算数。扫描到运算数，则入栈A中；扫描到运算符时，与栈B的栈顶运算符比较，若栈顶运算符优先级较低，则入栈；若栈顶运算符优先级较高，则弹出栈B顶运算符，弹出栈A两个运算数（若为单元素操作符，只弹出一个元素），将运算结果压入栈A。 队列队列的特性与栈结构正好相反，其主要性能是先进先出(FIFO)。具体实现方式与栈结构类似，这里不过多叙述。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-列表]]></title>
    <url>%2F2018%2F03%2F05%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[本篇文章整理《数据结构（C++语言版）》关于列表这种线性结构知识点。 列表在数据结构1——向量中介绍了线性表的两种形式：其一是物理地址与逻辑地址均连续，典型示例向量（Vector）结构；另一种是逻辑地址连续而物理地址不一定连续，典型示例列表（List）结构。列表结构的基本组成单位是节点（node），各节点通过指针或引用彼此连接，构成逻辑连续的序列。正因为列表这一特性，一些静态操作，如寻秩访问、find等方法无法高效完成（物理地址不连续）；而相反的动态操作，如插入、删除等方法无须对后续元素一次进行移位，故可以高效完成。 列表节点一个节点的形式如下图所以，包括节点具体数值data，以及它的前驱指向pred，后继指向succ。123456789101112#define Posi(T) ListNode&lt;T&gt;*template &lt;typename T&gt;struct ListNode &#123; T data; //数值 Posi(T) pred; //前驱 Posi(T) succ; //后继 ListNode() &#123;&#125; //针对header与trailer的构造，默认构造函数 ListNode(T e, Posi(T) p = NULL, Posi(T) s = NULL) : data(e), pred(p), succ(s) &#123;&#125; //默认构造器，成员初始化列表 Posi(T) insertAsPred(T const&amp; e); //前插入 Posi(T) insertAsSucc(T const&amp; e); //后插入&#125; TIPS：成员初始化列表在上述代码段中，ListNode(T e, Posi(T) p = NULL, Posi(T) s = NULL) : data(e), pred(p), succ(s) {}即为成员初始化列表。【注意：成员初始化顺序应按照类成员声明顺序】 前插入算法在当前节点前插入一个新的节点作为当前节点的前驱，需要修改原前驱的后继指向新节点等一系列如下图的操作。12345template&lt;typename T&gt;Posi(T) ListNode&lt;T&gt;::insertAsPred(T const&amp; e) &#123; Posi(T) x = new ListNode(e, pred, this); //初始化新节点data=e,pred=pred,succ=this,如上图（b） pred-&gt;succ = x; pred = x; return x;&#125; 列表模板类在列表中，预先定义了头、尾哨兵元素，并默认为不可见节点。 123456789101112#include "ListNode.h" //引入列表节点类template&lt;typename T&gt; class List &#123;private: int _size; Posi(T) header; Posi(T) trailer; //头、尾哨兵protected: /*...内部函数 */public: /*...构造函数、析构函数等...*/&#125; 列表初始化列表初始化，即创建头尾哨兵节点。具体代码实现如下123456789template&lt;typename T&gt;void List&lt;T&gt;::init() &#123; header = new ListNode&lt;T&gt;; trailer = new ListNode&lt;T&gt;;//到目前为止，头尾哨兵节点只调用ListNode结构中的默认构造方法，即设置其前驱pred与后继succ均为空，data也为空。 header-&gt;succ = trailer; hdader-&gt;pred = NULL; trailer-&gt;pred = header; trailer-&gt;succ = NULL; _size = 0;&#125; 初始化列表后，头尾哨兵节点创建完成，但默认为不可见，内部可见元素通过其他方法进行插入补充。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-向量]]></title>
    <url>%2F2018%2F03%2F05%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%90%91%E9%87%8F%2F</url>
    <content type="text"><![CDATA[本篇文章整理《数据结构（C++语言版）》关于向量这种线性结构知识点。 线性表 线性表是最基本、最简单、也是最常用的一种数据结构。线性表中数据元素之间的关系是一对一的关系，即除了第一个和最后一个数据元素之外，其它数据元素都是首尾相接的。线性表有两种存储方式，一种是顺序存储结构，另一种是链式存储结构。即，一种是物理地址与逻辑地址均连续，另一种是只有逻辑地址连续。 向量向量结构是一种顺序存储结构，即其物理地址与逻辑地址均连续（数组array是一种无序向量实例）。向量可以通过寻秩访问进行快速定位向量中某一元素，与此同时，由于其物理地址连续性，向量在删减或添加某个元素时，需对被修改位置之后的所有元素依次向前（后）移动，以保证其物理地址连续性。 遍历对向量中所有元素实施某种统一操作。具体有两种采用方式，前一种是借助函数指针*visit()指定某一函数；后者 借助函数对象机制，通过将操作符”()”重载后，使其调用方式可以如同函数一样。123456789101112131415template&lt;typename T&gt;void Vector&lt;T&gt;::traverse(void (*visit) (T&amp;) ) &#123; //借助函数指针 for(int i = 0; i &lt; _size; i++)&#123; //函数指针调用可以为visit(),也可使用(*visit)()，但前者更合适 visit( _elem[i]); &#125;&#125;template&lt;typename T&gt; template&lt;typename VST&gt;void Vector&lt;T&gt;::traverse(VST&amp; visit ) &#123; //借助函数对象 for(int i = 0; i &lt; _size; i++)&#123; //函数指针调用可以为visit(),也可使用(*visit)()，但前者更合适 visit( _elem[i]); &#125;&#125; 实例12345678template &lt;typename T&gt; struct Increase&#123; //函数对象 virtual void operator() (T&amp; e) &#123;e++;&#125;&#125;template &lt;typename T&gt; void Vector&lt;T&gt;::increase( Vector&lt;T&gt;&amp; V) &#123; V.traverse( Increase&lt;T&gt;() );&#125; 唯一化无序向量算法：从第二个元素开始，在其前缀中查找相同元素，若存在雷同者，删除当前（最后一个相同元素）。这种算法下，每次最多只有一个相同元素需要去除。12345678910template &lt;typename T&gt;int Vector&lt;T&gt;::deduplicate()&#123; int oldSize = _size; //记录原始长度 Rank i = 1; while(i &lt; _size)&#123; (find(_elem[i], 0, i) ) &lt; 0 ? //查找当前元素前缀中是否有雷同 i++ : remove( i ); &#125; return oldSize - _size;&#125; 有序向量算法：对于有序向量，相同元素彼此相邻。设置入选元素_elem[i]与待入选元素_elem[j]，比较二者，相同则忽略，不同则将j对应元素赋值i的后继，以此类推。12345678910template &lt;typename T&gt;int Vector&lt;T&gt;::uniquify() &#123; //有序向量去重 Rank i = 0, j = 1; while(j&lt;_size)&#123; (_elem[i] == _elem[j]) ? j++ : _elem[++i] = _elem[j]; &#125; ++i = _size; shrink(); //截除多余元素 return j - i;&#125; 查找无序向量算法：从后往前，找到该元素对应秩最大者。代码：略。有序向量对有序向量而言，通常采用减而治之的策略。即将所查找的区间分段，分别核实待查元素是落入左区间还是右区间亦或是中点位置，再反复迭代。为了优化算法。一种方法是增加代价小的一方深度，即将区间点不再设置为中点，转而设置Fibonacci节点，使得左区间包含元素更多（代价小）；另一种方法，即将中转点包含入右区间中，使得左右区间代价相等（都只需经过一次判断）。算法：待续….]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chinese-Whisper,一种简洁分类方法]]></title>
    <url>%2F2018%2F03%2F05%2F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91-Chinese-Whisper-%E4%B8%80%E7%A7%8D%E7%AE%80%E6%B4%81%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[写在前面近来利用神经网络提取人脸特征的方法越来越多，人脸相似性匹配准确度也越来越高。但仍然没有找到一种适合于未知类别数量，自动划分的方法，而k-means等聚类方法均是要预先设定分类数量后再开始进行聚类操作。在博客的介绍下，了解了一种比较简单的无监督分类方法，chinese-whisper。现将具体实验总结如下… CW-算法【适用场景】未知具体分类数量，自动查找类别个数并进行快速聚类。【算法核心】初始化构建无向图，以每个节点为一个类别，不同节点之间计算相似度，当相似度超过threshold，将两个节点相连形成关联边，权重为相似度。迭代1.随机选取一个节点i开始，在其邻居中选取边权重最大者j，并将该点归为节点j类（若邻居中有多个节点(j,k,l)属于同一类，则将这些节点权重相加再参与比较）。2.遍历所有节点后，重复迭代至满足迭代次数。【算法分析】1.特征向量高要求从算法介绍可以看出，该算法即是对两两匹配的升级。因而该算法一个很大影响因素即为门限threshold的选取。算法的准确度又会回归到神经网络的核心要求，增大类间间距，减小类内间距。另外，该算法对于类别数较多的情况下，可能会有较差的结果，即类别越多，当前空间下的特征向量区分性越差。2.随机性较大该算法的一个重大缺陷在于其随机性较大。究其原因，每次迭代会随机选取开始节点，因而对于模糊节点而言，不同遍历次序会使该节点被归在不同类别中。对于上图，正确分类为{1,2}，{3,4,5}。然而由于特征向量表现度不够，3节点归类较为模糊。若遍历次序为1→2→3，节点{1,2}会优先归在同一类，导致3节点有更大可能性被归属于{1,2,3}，因为此时{4}，{5}仍是独立类别。若遍历次序为4→5→3，节点{4,5}会优先归在同一类，导致3节点有更大可能性被归属于{3,4,5}，因为此时{1}，{2}仍是独立类别。 算法测试【测试来源】数据集为提取的lfw人脸最多的前19种，网络模型为mtcnn+resnet11。【测试步骤】分别选取2,3,4,5类用于分类情况测试，考虑到随机性，每个类别各测试5次。【详细性能】测试结果如下图，图中分类错误已用红笔圈出。2-class采用2个分类集时，样本数量一共119张，其中0-76属于第一类，77-118属于第二类。准确率–100%说明：由于5次测试结果相同，这里不再添加。 3-class采用3个分类集时，样本数量一共355张，其中0-76属于第一类，77-118属于第二类，119-354属于第三类。准确率–2个错误说明：由于5次测试结果相同，这里不再添加。 4-class采用4个分类集时，样本数量一共476张，其中0-76属于第一类，77-118属于第二类，119-354属于第三类,355-475属于第四类。 准确率–无法恒定。出现2中分类情况，见下图第一种情况，只分出了3个类别，错误将第四类归在图中第二类第二种情况，成功区分4个类别。准确率–6个错误 5-class采用5个分类集时，样本数量一共1006张，其中0-76属于第一类，77-118属于第二类，119-354属于第三类,355-475属于第四类,476-1005属于第五类。 准确率–很差。见下图​除了119-354分类准确，其他全部归为了图中第0类。5-class采用5个分类集，每40张一类。出现随机现象。 【详细代码】123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186# -*-coding:utf-8 -*-def face_distance(face_encodings, face_to_compare): """ 计算一组特征值与带比较特征值之间的距离，默认采用欧氏距离 参数配置 face_encodings:一组特征值，包含多个 face_to_compare:待比较特征值，只有一个 return:返回不同特征向量之间距离的数组矩阵 """ import numpy as np if len(face_encodings) == 0: return np.empty((0)) ''' 利用numpy包进行距离估量 http://blog.csdn.net/u013749540/article/details/51813922 ''' dist=[] """ # 欧氏距离，考虑后续邻接边选择weight较大者，此处选取余弦相似度 for i in range(0,len(face_encodings)): #sim = 1.0/(1.0+np.linalg.norm(face_encodings[i]-face_to_compare)) sim=np.linalg.norm(face_encodings[i]-face_to_compare) dist.append(sim) """ # 余弦相似度 for i in range(0, len(face_encodings)): num=np.dot(face_encodings[i],face_to_compare) cos=num/(np.linalg.norm(face_encodings[i])*np.linalg.norm(face_to_compare)) sim=0.5+0.5*cos # 归一化 dist.append(sim) return distdef find_all_index(arr,item): '''获取list中相同元素的索引 输入： arr：待求取list item：待获取元素 输出： 相同元素索引，格式为list''' return [i for i, a in enumerate(arr) if a==item]def _chinese_whispers(threshold=0.675, iterations=10): """ Chinese Whisper Algorithm 算法概要 1.初始化每个节点为一个类 2.选取任意节点开始迭代 选择该节点邻居中边权重最大者，将两则归为一类；若邻居中有2者以上属于同一类，将这些类权重相加进行比较 输入： encoding_list:待分类的特征向量组 threshold:判断门限，判断两个向量是否相关 iteration:迭代次数 输出： sorted_clusters:一组分类结果，按从大到小排列 """ from random import shuffle import networkx as nx import numpy as np import re # Create graph nodes = [] edges = [] #encoding_list格式为 #[(path1,encode1),(path2,encode2),(path3,encode3)] #image_paths, encodings = zip(*encoding_list) feature_matrix=np.loadtxt(r'F:\5.txt') encodings=[] #image_paths=[] for i in range(0,len(feature_matrix)): encodings.append(feature_matrix[i,:]) #image_paths.append(r'F:\outCluster\%d\\' %i) if len(encodings) &lt;= 1: print ("No enough encodings to cluster!") return [] ''' 节点初始化： 1.将每个特征向量设为一个类 2.计算每个特征向量之间的距离，并根据门限判定是否构成邻接边 ''' for idx, face_encoding_to_check in enumerate(encodings): # Adding node of facial encoding node_id = idx # 节点属性包括 # node_id:节点id,(0,n-1) # label:节点类别，初始化每个节点一个类别 # path：节点导出路径，用于图片分类导出 node = (node_id, &#123;'label':idx&#125;) #node = (node_id, &#123;'label': idx, 'path': image_paths[idx]&#125;) nodes.append(node) # Facial encodings to compare if (idx+1) &gt;= len(encodings): # Node is last element, don't create edge break #构造比较向量组 #若当前向量为i,则比较向量组为[i+1:n] compare_encodings = encodings[idx+1:] distances = face_distance(compare_encodings, face_encoding_to_check) encoding_edges = [] for i, distance in enumerate(distances): # 若人脸特征匹配，则在这两个节点间添加关联边 if distance &gt;= threshold: #edge_id：与node_id相连接的节点的node_id edge_id = idx+i+1 encoding_edges.append((node_id, edge_id, &#123;'weight': distance&#125;)) edges = edges + encoding_edges G = nx.Graph() G.add_nodes_from(nodes) G.add_edges_from(edges) ''' 迭代过程 ''' for _ in range(0, iterations): cluster_nodes = list(G.nodes()) #返回节点id shuffle(cluster_nodes)# 随机选取一个开始节点 for node in cluster_nodes: # 当前节点的所有邻接边，如节点4邻接边为(4,5,weight=8)(4,8,weight=10) # 则G[4]返回值为AtlasView(&#123;5:&#123;'weight':8&#125;, 8:&#123;'weight':10&#125;&#125;) neighbors = G[node] # cluster形式 # &#123;'cluster_path':weight&#125; 其中cluster_paht=node属性的cluster值 labels = &#123;&#125; for ne in neighbors: # ne即为当前节点邻接的节点id if isinstance(ne, int): ''' 判断该邻居的类别是否在其他邻居中存在 若存在，则将相同类别的权重相加。 ''' if G.node[ne]['label'] in labels:#G.node[ne]['label']即为id=ne节点的label属性 labels[G.node[ne]['label']] += G[node][ne]['weight']#将这条邻接边(node,ne)的weight属性赋值给cluster[节点ne的cluster] else: labels[G.node[ne]['label']] = G[node][ne]['weight'] # find the class with the highest edge weight sum edge_weight_sum = 0 max_cluster = 0 #将邻居节点的权重最大值对应的文件路径给到当前节点 #这里cluster即为path for id in labels: if labels[id] &gt; edge_weight_sum: edge_weight_sum = labels[id] max_cluster = id # set the class of target node to the winning local class #print('node %s was clustered in %s' %(node, max_cluster)) G.node[node]['label'] = max_cluster list_label_out = [] for i in range(len(encodings)): list_label_out.append(G.node[i]['label']) #print(list_label_out) ''' 统计分类错误数量=新类别中不属于原类别的数量 eg： list_label_out=[1,3,4,2,2,4,3,1] # group_all 返回最终类别标签 group_all=[1,2,3,4] # group_num 最终分类数量 group_num=4 # group_cluster: list,返回相同标签的节点id group_cluster=[[0,7],[3,4],[1,6],[2,5]] ''' group_all = set(list_label_out) group_num = len(group_all) group_cluster = [] for item in group_all: group_cluster.append(find_all_index(list_label_out,item)) print('最终分类数量：%s' %group_num) for i in range(0,group_num): print('第%d类：%s'%(i,group_cluster[i]))if __name__ == '__main__': _chinese_whispers()]]></content>
      <categories>
        <category>程序开发</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
</search>
